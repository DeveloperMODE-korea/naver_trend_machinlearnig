"""
AI ë¦¬í¬íŠ¸ ìƒì„± ëª¨ë“ˆ

Claude AI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ í•´ì„í•˜ê³  
ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any
import json
from datetime import datetime
import os

try:
    import anthropic
    CLAUDE_AVAILABLE = True
except ImportError:
    CLAUDE_AVAILABLE = False
    print("âš ï¸  Claude AI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install anthropicìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

from ..config import Config

class AIReporter:
    """Claude AI ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: Optional[str] = None):
        """ì´ˆê¸°í™”
        
        Args:
            api_key: Claude API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
        """
        if not CLAUDE_AVAILABLE:
            self.client = None
            return
        
        # API í‚¤ ì„¤ì •
        self.api_key = api_key or os.getenv("CLAUDE_API_KEY")
        
        if self.api_key:
            try:
                self.client = anthropic.Anthropic(api_key=self.api_key)
                print("âœ… Claude AI ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ Claude AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.client = None
        else:
            print("âš ï¸  Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.client = None
    
    def is_available(self) -> bool:
        """AI ë¦¬í¬íŠ¸ ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.client is not None
    
    def generate_data_analysis_report(self, data_df: pd.DataFrame, 
                                    statistics_results: Dict = None,
                                    correlation_matrix: pd.DataFrame = None,
                                    growth_rates: pd.DataFrame = None) -> str:
        """ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ AIê°€ í•´ì„í•˜ëŠ” ë¦¬í¬íŠ¸ ìƒì„±"""
        
        if not self.is_available():
            return "âŒ AI ë¦¬í¬íŠ¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Claude API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        
        # ë°ì´í„° ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
        summary_info = self._extract_data_summary(data_df, statistics_results, correlation_matrix, growth_rates)
        
        # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._create_analysis_prompt(summary_info)
        
        try:
            # Claude AIì—ê²Œ ë¶„ì„ ìš”ì²­
            response = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=3000,
                temperature=0.3,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            ai_report = response.content[0].text
            
            # ë¦¬í¬íŠ¸ í—¤ë” ì¶”ê°€
            report_header = f"""
ğŸ¤– **Claude AI ë¶„ì„ ë¦¬í¬íŠ¸**
ğŸ“… ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ“Š ë¶„ì„ ë°ì´í„°: {len(data_df)}ê°œ í¬ì¸íŠ¸, {len(data_df['keyword'].unique())}ê°œ í‚¤ì›Œë“œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
            
            return report_header + ai_report
            
        except Exception as e:
            return f"âŒ AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def generate_prediction_report(self, prediction_results: Dict[str, pd.DataFrame]) -> str:
        """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ AIê°€ í•´ì„í•˜ëŠ” ë¦¬í¬íŠ¸ ìƒì„±"""
        
        if not self.is_available():
            return "âŒ AI ë¦¬í¬íŠ¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½
        prediction_summary = self._extract_prediction_summary(prediction_results)
        
        # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._create_prediction_prompt(prediction_summary)
        
        try:
            response = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=2500,
                temperature=0.3,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            ai_report = response.content[0].text
            
            report_header = f"""
ğŸ”® **Claude AI ì˜ˆì¸¡ ë¶„ì„ ë¦¬í¬íŠ¸**
ğŸ“… ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ¯ ì˜ˆì¸¡ í‚¤ì›Œë“œ: {', '.join(prediction_results.keys())}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
            
            return report_header + ai_report
            
        except Exception as e:
            return f"âŒ AI ì˜ˆì¸¡ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    def generate_quality_report(self, quality_assessment: Dict, outlier_results: Dict = None) -> str:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ë¥¼ AIê°€ í•´ì„í•˜ëŠ” ë¦¬í¬íŠ¸ ìƒì„±"""
        
        if not self.is_available():
            return "âŒ AI ë¦¬í¬íŠ¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # í’ˆì§ˆ ì •ë³´ ìš”ì•½
        quality_summary = self._extract_quality_summary(quality_assessment, outlier_results)
        
        # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._create_quality_prompt(quality_summary)
        
        try:
            response = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=2000,
                temperature=0.3,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            ai_report = response.content[0].text
            
            report_header = f"""
ğŸ” **Claude AI í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸**
ğŸ“… ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ’¯ í’ˆì§ˆ ì ìˆ˜: {quality_assessment['overall_score']:.1f}ì  ({quality_assessment['quality_grade']})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
            
            return report_header + ai_report
            
        except Exception as e:
            return f"âŒ AI í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    def generate_business_insights(self, keywords: List[str], 
                                 market_data: pd.DataFrame,
                                 industry_context: str = "ì¼ë°˜ ì†Œë¹„ì¬") -> str:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë° ì „ëµ ì œì•ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        if not self.is_available():
            return "âŒ AI ë¦¬í¬íŠ¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì‹œì¥ ë°ì´í„° ìš”ì•½
        market_summary = self._extract_market_summary(keywords, market_data, industry_context)
        
        # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._create_business_prompt(market_summary)
        
        try:
            response = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=3500,
                temperature=0.4,  # ì°½ì˜ì  ì œì•ˆì„ ìœ„í•´ ì˜¨ë„ ì•½ê°„ ë†’ì„
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            ai_report = response.content[0].text
            
            report_header = f"""
ğŸ’¼ **Claude AI ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸**
ğŸ“… ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ­ ì‚°ì—… ë¶„ì•¼: {industry_context}
ğŸ¯ ë¶„ì„ í‚¤ì›Œë“œ: {', '.join(keywords)}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
            
            return report_header + ai_report
            
        except Exception as e:
            return f"âŒ AI ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    def _extract_data_summary(self, data_df: pd.DataFrame, 
                            statistics_results: Dict = None,
                            correlation_matrix: pd.DataFrame = None,
                            growth_rates: pd.DataFrame = None) -> Dict:
        """ë°ì´í„° ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì •ë³´ ì¶”ì¶œ"""
        
        keywords = data_df['keyword'].unique().tolist()
        
        # ê¸°ë³¸ í†µê³„
        basic_stats = {}
        for keyword in keywords:
            keyword_data = data_df[data_df['keyword'] == keyword]['ratio']
            basic_stats[keyword] = {
                'mean': float(keyword_data.mean()),
                'std': float(keyword_data.std()),
                'min': float(keyword_data.min()),
                'max': float(keyword_data.max()),
                'trend': 'increasing' if keyword_data.iloc[-5:].mean() > keyword_data.iloc[:5].mean() else 'decreasing'
            }
        
        # ìƒê´€ê´€ê³„ ìš”ì•½
        correlation_summary = {}
        if correlation_matrix is not None:
            for i, keyword1 in enumerate(keywords):
                for j, keyword2 in enumerate(keywords):
                    if i < j:  # ì¤‘ë³µ ì œê±°
                        corr_value = correlation_matrix.loc[keyword1, keyword2]
                        if abs(corr_value) > 0.5:  # ê°•í•œ ìƒê´€ê´€ê³„ë§Œ
                            correlation_summary[f"{keyword1}-{keyword2}"] = float(corr_value)
        
        # ì„±ì¥ë¥  ìš”ì•½
        growth_summary = {}
        if growth_rates is not None:
            for _, row in growth_rates.iterrows():
                growth_summary[row['í‚¤ì›Œë“œ']] = float(row['ì„±ì¥ë¥ (%)'])
        
        return {
            'keywords': keywords,
            'data_period': f"{data_df['date'].min().strftime('%Y-%m')} ~ {data_df['date'].max().strftime('%Y-%m')}",
            'total_data_points': len(data_df),
            'basic_statistics': basic_stats,
            'correlations': correlation_summary,
            'growth_rates': growth_summary
        }
    
    def _extract_prediction_summary(self, prediction_results: Dict[str, pd.DataFrame]) -> Dict:
        """ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ ì •ë³´ ì¶”ì¶œ"""
        
        summary = {}
        
        for keyword, result_df in prediction_results.items():
            predictions = result_df['ì•™ìƒë¸” ì˜ˆì¸¡'].values
            confidence = result_df['ì‹ ë¢°ë„'].mean()
            
            # íŠ¸ë Œë“œ ë¶„ì„
            trend = 'increasing' if predictions[-1] > predictions[0] else 'decreasing'
            volatility = np.std(predictions)
            
            summary[keyword] = {
                'predictions': predictions.tolist(),
                'average_confidence': float(confidence),
                'trend': trend,
                'volatility': float(volatility),
                'peak_month': int(np.argmax(predictions) + 1),
                'lowest_month': int(np.argmin(predictions) + 1)
            }
        
        return summary
    
    def _extract_quality_summary(self, quality_assessment: Dict, outlier_results: Dict = None) -> Dict:
        """í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ ìš”ì•½ ì •ë³´ ì¶”ì¶œ"""
        
        return {
            'overall_score': quality_assessment['overall_score'],
            'quality_grade': quality_assessment['quality_grade'],
            'metrics': quality_assessment['quality_metrics'],
            'alerts': [alert['message'] for alert in quality_assessment.get('alerts', [])],
            'recommendations': quality_assessment.get('recommendations', []),
            'outlier_info': outlier_results['summary'] if outlier_results else None
        }
    
    def _extract_market_summary(self, keywords: List[str], market_data: pd.DataFrame, industry_context: str) -> Dict:
        """ì‹œì¥ ë°ì´í„° ìš”ì•½ ì •ë³´ ì¶”ì¶œ"""
        
        # í‚¤ì›Œë“œë³„ ì‹œì¥ í¬ì§€ì…˜ ë¶„ì„
        keyword_positions = {}
        for keyword in keywords:
            keyword_data = market_data[market_data['keyword'] == keyword]['ratio']
            if not keyword_data.empty:
                avg_performance = keyword_data.mean()
                recent_trend = keyword_data.iloc[-6:].mean() - keyword_data.iloc[-12:-6].mean()
                
                keyword_positions[keyword] = {
                    'average_performance': float(avg_performance),
                    'recent_trend': float(recent_trend),
                    'market_share_rank': None  # ìƒëŒ€ì  ìˆœìœ„ëŠ” ê³„ì‚° ê°€ëŠ¥
                }
        
        return {
            'industry_context': industry_context,
            'keywords': keywords,
            'keyword_positions': keyword_positions,
            'analysis_period': f"{market_data['date'].min().strftime('%Y-%m')} ~ {market_data['date'].max().strftime('%Y-%m')}"
        }
    
    def _create_analysis_prompt(self, summary_info: Dict) -> str:
        """ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        return f"""
ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¥ ì „ë¬¸ê°€ì´ì ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë„¤ì´ë²„ ì‡¼í•‘ íŠ¸ë Œë“œ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ë¶„ì„ ë°ì´í„° ì •ë³´
- ë¶„ì„ í‚¤ì›Œë“œ: {', '.join(summary_info['keywords'])}
- ë¶„ì„ ê¸°ê°„: {summary_info['data_period']}
- ì´ ë°ì´í„° í¬ì¸íŠ¸: {summary_info['total_data_points']}ê°œ

## í‚¤ì›Œë“œë³„ ê¸°ë³¸ í†µê³„
{json.dumps(summary_info['basic_statistics'], indent=2, ensure_ascii=False)}

## ì£¼ìš” ìƒê´€ê´€ê³„ (0.5 ì´ìƒ)
{json.dumps(summary_info['correlations'], indent=2, ensure_ascii=False)}

## ì„±ì¥ë¥  ë¶„ì„
{json.dumps(summary_info['growth_rates'], indent=2, ensure_ascii=False)}

ë‹¤ìŒ êµ¬ì¡°ë¡œ í•œêµ­ì–´ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸ“Š í•µì‹¬ ë°œê²¬ì‚¬í•­
- ê°€ì¥ ì£¼ëª©í•  ë§Œí•œ 3ê°€ì§€ íŠ¸ë Œë“œ

## ğŸ” í‚¤ì›Œë“œë³„ ìƒì„¸ ë¶„ì„
- ê° í‚¤ì›Œë“œì˜ ì„±ê³¼ì™€ íŠ¹ì§• ë¶„ì„
- ì‹œì¥ì—ì„œì˜ ìœ„ì¹˜ì™€ ì˜ë¯¸

## ğŸ”— í‚¤ì›Œë“œ ê°„ ê´€ê³„ ë¶„ì„
- ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” í‚¤ì›Œë“œë“¤ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸
- ê²½ìŸ ê´€ê³„ ë˜ëŠ” ë³´ì™„ ê´€ê³„ ë¶„ì„

## ğŸ“ˆ ì‹œì¥ íŠ¸ë Œë“œ í•´ì„
- ì „ì²´ì ì¸ ì‹œì¥ íë¦„ê³¼ íŒ¨í„´
- ê³„ì ˆì„±ì´ë‚˜ íŠ¹ë³„í•œ ì´ë²¤íŠ¸ì˜ ì˜í–¥

## ğŸ’¡ ì „ëµì  ì‹œì‚¬ì 
- ê° í‚¤ì›Œë“œì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì œì•ˆ
- í–¥í›„ ì£¼ëª©í•´ì•¼ í•  í‚¤ì›Œë“œë‚˜ íŠ¸ë Œë“œ

ì „ë¬¸ì ì´ë©´ì„œë„ ì‹¤ë¬´ì§„ì´ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
"""
    
    def _create_prediction_prompt(self, prediction_summary: Dict) -> str:
        """ì˜ˆì¸¡ ë¶„ì„ì„ ìœ„í•œ AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        return f"""
ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¥ ì „ë¬¸ê°€ì´ì ë¯¸ë˜ ì˜ˆì¸¡ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë„¤ì´ë²„ ì‡¼í•‘ íŠ¸ë Œë“œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¯¸ë˜ ì‹œì¥ ì „ë§ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½
{json.dumps(prediction_summary, indent=2, ensure_ascii=False)}

ë‹¤ìŒ êµ¬ì¡°ë¡œ í•œêµ­ì–´ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸ”® ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½
- ê° í‚¤ì›Œë“œì˜ í–¥í›„ 6ê°œì›” ì „ë§ í•œ ë¬¸ì¥ ìš”ì•½

## ğŸ“Š í‚¤ì›Œë“œë³„ ë¯¸ë˜ ì „ë§
- ì˜ˆì¸¡ëœ íŠ¸ë Œë“œ ë°©í–¥ê³¼ ë³€ë™ì„± ë¶„ì„
- ì‹ ë¢°ë„ í‰ê°€ ë° ì£¼ì˜ì‚¬í•­
- í”¼í¬ ì‹œì ê³¼ ì €ì  ì‹œì ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸

## âš¡ ì£¼ìš” ê¸°íšŒì™€ ìœ„í—˜
- ì„±ì¥ì´ ì˜ˆìƒë˜ëŠ” í‚¤ì›Œë“œì˜ ê¸°íšŒ ìš”ì¸
- í•˜ë½ì´ ì˜ˆìƒë˜ëŠ” í‚¤ì›Œë“œì˜ ìœ„í—˜ ìš”ì¸
- ì‹œì¥ ë³€í™”ì— ëŒ€ë¹„í•œ ì „ëµ

## ğŸ“… ì›”ë³„ ì‹¤í–‰ ê³„íš
- ê° ì›”ë³„ë¡œ ì§‘ì¤‘í•´ì•¼ í•  í‚¤ì›Œë“œ
- ë§ˆì¼€íŒ… ë° ì¬ê³  ê´€ë¦¬ íƒ€ì´ë°

## ğŸ¯ ì¶”ì²œ ì•¡ì…˜ ì•„ì´í…œ
- ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  í–‰ë™ ê³„íš
- ì¤‘ì¥ê¸° ì „ëµ ë°©í–¥

ì˜ˆì¸¡ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ì¸ì •í•˜ë©´ì„œë„ ì‹¤ë¬´ì§„ì´ ì˜ì‚¬ê²°ì •ì— í™œìš©í•  ìˆ˜ ìˆëŠ” ëª…í™•í•œ ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
    
    def _create_quality_prompt(self, quality_summary: Dict) -> str:
        """í’ˆì§ˆ ë¶„ì„ì„ ìœ„í•œ AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        return f"""
ë‹¹ì‹ ì€ ë°ì´í„° í’ˆì§ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì„ ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.

## í’ˆì§ˆ í‰ê°€ ê²°ê³¼
- ì „ì²´ ì ìˆ˜: {quality_summary['overall_score']:.1f}ì 
- í’ˆì§ˆ ë“±ê¸‰: {quality_summary['quality_grade']}
- í’ˆì§ˆ ë©”íŠ¸ë¦­: {json.dumps(quality_summary['metrics'], indent=2, ensure_ascii=False)}

## ë°œê²¬ëœ ë¬¸ì œì 
{quality_summary['alerts']}

## ê¸°ì¡´ ê¶Œì¥ì‚¬í•­
{quality_summary['recommendations']}

## ì´ìƒì¹˜ ì •ë³´
{json.dumps(quality_summary['outlier_info'], indent=2, ensure_ascii=False) if quality_summary['outlier_info'] else "ì´ìƒì¹˜ ì •ë³´ ì—†ìŒ"}

ë‹¤ìŒ êµ¬ì¡°ë¡œ í•œêµ­ì–´ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸ” ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨
- í˜„ì¬ ë°ì´í„° í’ˆì§ˆ ìˆ˜ì¤€ì˜ ì „ë°˜ì  í‰ê°€
- ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë„

## âš ï¸ ì£¼ìš” ë¬¸ì œì  ë¶„ì„
- ê° í’ˆì§ˆ ì´ìŠˆì˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„
- ë¬¸ì œì˜ ìš°ì„ ìˆœìœ„ì™€ ì˜í–¥ë„ í‰ê°€

## ğŸ› ï¸ ì¦‰ì‹œ ê°œì„  ë°©ì•ˆ
- ë‹¨ê¸°ê°„ì— ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  í•´ê²°ì±…
- ê° ë°©ì•ˆì˜ ì˜ˆìƒ íš¨ê³¼ì™€ ì†Œìš” ì‹œê°„

## ğŸ“ˆ ì¥ê¸° í’ˆì§ˆ ê°œì„  ì „ëµ
- ê·¼ë³¸ì  í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì‹œìŠ¤í…œ ê°œì„ ì•ˆ
- ì§€ì†ì  ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶• ë°©ì•ˆ

## âœ… í’ˆì§ˆ ê´€ë¦¬ ì²´í¬ë¦¬ìŠ¤íŠ¸
- ì¼ìƒì ìœ¼ë¡œ í™•ì¸í•´ì•¼ í•  í’ˆì§ˆ ì§€í‘œ
- ë¬¸ì œ ë°œìƒ ì‹œ ëŒ€ì‘ ì ˆì°¨

ì‹¤ë¬´ì§„ì´ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.
"""
    
    def _create_business_prompt(self, market_summary: Dict) -> str:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ìœ„í•œ AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        return f"""
ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¥ ì „ë¬¸ê°€ì´ì ê²½ì˜ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‹œì¥ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ì‹œì¥ ë¶„ì„ ì •ë³´
- ì‚°ì—… ë¶„ì•¼: {market_summary['industry_context']}
- ë¶„ì„ í‚¤ì›Œë“œ: {', '.join(market_summary['keywords'])}
- ë¶„ì„ ê¸°ê°„: {market_summary['analysis_period']}

## í‚¤ì›Œë“œë³„ ì‹œì¥ í¬ì§€ì…˜
{json.dumps(market_summary['keyword_positions'], indent=2, ensure_ascii=False)}

ë‹¤ìŒ êµ¬ì¡°ë¡œ í•œêµ­ì–´ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸª ì‹œì¥ í™˜ê²½ ë¶„ì„
- {market_summary['industry_context']} ì‹œì¥ì˜ í˜„ì¬ ìƒí™©
- ì£¼ìš” íŠ¸ë Œë“œì™€ ì†Œë¹„ì í–‰ë™ ë³€í™”

## ğŸ¯ í‚¤ì›Œë“œë³„ ì „ëµ í¬ì§€ì…”ë‹
- ê° í‚¤ì›Œë“œì˜ ì‹œì¥ ë‚´ ìœ„ì¹˜ì™€ ê²½ìŸë ¥
- ì„±ì¥ ì ì¬ë ¥ê³¼ ì‹œì¥ ê¸°íšŒ í‰ê°€

## ğŸ’° ìˆ˜ìµì„± ë¶„ì„
- ë†’ì€ ìˆ˜ìµì„±ì´ ì˜ˆìƒë˜ëŠ” í‚¤ì›Œë“œ
- íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ê°€ í° ì˜ì—­

## ğŸš€ ì„±ì¥ ì „ëµ ì œì•ˆ
- ë‹¨ê¸° ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì „ëµ
- ì¤‘ì¥ê¸° ì‚¬ì—… í™•ì¥ ë°©í–¥

## âš”ï¸ ê²½ìŸ ëŒ€ì‘ ì „ëµ
- ê²½ìŸì‚¬ ëŒ€ë¹„ ì°¨ë³„í™” í¬ì¸íŠ¸
- ì‹œì¥ ì ìœ ìœ¨ í™•ëŒ€ ë°©ì•ˆ

## ğŸ“Š ì„±ê³¼ ì¸¡ì • ì§€í‘œ
- ì „ëµ ì‹¤í–‰ í›„ ëª¨ë‹ˆí„°ë§í•  KPI
- ì„±ê³µ ê¸°ì¤€ê³¼ ìˆ˜ì • ì‹œì 

## ğŸ”® ë¯¸ë˜ ì‹œë‚˜ë¦¬ì˜¤
- ë² ìŠ¤íŠ¸/ì›ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤
- ê° ìƒí™©ë³„ ëŒ€ì‘ ê³„íš

{market_summary['industry_context']} ì—…ê³„ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”.
"""
    
    def save_report(self, report_content: str, report_type: str, filename: str = None) -> str:
        """AI ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ai_report_{report_type}_{timestamp}.md"
        
        filepath = os.path.join(Config.SAVE_DIR, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"âœ… AI ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {filepath}")
            return filepath
        except Exception as e:
            print(f"âŒ AI ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""