"""
ì´ìƒì¹˜ íƒì§€ ëª¨ë“ˆ

í†µê³„ì  ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ ì´ìƒì¹˜ë¥¼ íƒì§€í•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from scipy import stats
import matplotlib.pyplot as plt
from ..config import Config

class OutlierDetector:
    """ì´ìƒì¹˜ íƒì§€ í´ë˜ìŠ¤"""
    
    def __init__(self, methods: List[str] = ['iqr', 'zscore', 'isolation']):
        """ì´ˆê¸°í™”
        
        Args:
            methods: ì‚¬ìš©í•  ì´ìƒì¹˜ íƒì§€ ë°©ë²•ë“¤
                    - 'iqr': ì‚¬ë¶„ìœ„ìˆ˜ ë²”ìœ„ ë°©ë²•
                    - 'zscore': Z-ì ìˆ˜ ë°©ë²•  
                    - 'isolation': ê²©ë¦¬ í¬ë ˆìŠ¤íŠ¸ (ì¶”í›„ êµ¬í˜„)
        """
        self.methods = methods
        self.outlier_results = {}
    
    def detect_outliers_iqr(self, data: pd.Series, factor: float = 1.5) -> Tuple[np.ndarray, Dict]:
        """IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ë¥¼ íƒì§€í•©ë‹ˆë‹¤
        
        Args:
            data: ê²€ì‚¬í•  ë°ì´í„° ì‹œë¦¬ì¦ˆ
            factor: IQR ë°°ìˆ˜ (ê¸°ë³¸: 1.5)
            
        Returns:
            ì´ìƒì¹˜ ë§ˆìŠ¤í¬ì™€ í†µê³„ ì •ë³´
        """
        Q1 = data.quantile(0.25)
        Q3 = data.quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR
        
        outlier_mask = (data < lower_bound) | (data > upper_bound)
        
        stats_info = {
            'method': 'IQR',
            'Q1': Q1,
            'Q3': Q3,
            'IQR': IQR,
            'lower_bound': lower_bound,
            'upper_bound': upper_bound,
            'outlier_count': outlier_mask.sum(),
            'outlier_percentage': (outlier_mask.sum() / len(data)) * 100
        }
        
        return outlier_mask, stats_info
    
    def detect_outliers_zscore(self, data: pd.Series, threshold: float = 3.0) -> Tuple[np.ndarray, Dict]:
        """Z-ì ìˆ˜ ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ë¥¼ íƒì§€í•©ë‹ˆë‹¤
        
        Args:
            data: ê²€ì‚¬í•  ë°ì´í„° ì‹œë¦¬ì¦ˆ
            threshold: Z-ì ìˆ˜ ì„ê³„ê°’ (ê¸°ë³¸: 3.0)
            
        Returns:
            ì´ìƒì¹˜ ë§ˆìŠ¤í¬ì™€ í†µê³„ ì •ë³´
        """
        z_scores = np.abs(stats.zscore(data))
        outlier_mask = z_scores > threshold
        
        stats_info = {
            'method': 'Z-Score',
            'mean': data.mean(),
            'std': data.std(),
            'threshold': threshold,
            'max_zscore': z_scores.max(),
            'outlier_count': outlier_mask.sum(),
            'outlier_percentage': (outlier_mask.sum() / len(data)) * 100
        }
        
        return outlier_mask, stats_info
    
    def detect_outliers_modified_zscore(self, data: pd.Series, threshold: float = 3.5) -> Tuple[np.ndarray, Dict]:
        """ìˆ˜ì •ëœ Z-ì ìˆ˜ ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ë¥¼ íƒì§€í•©ë‹ˆë‹¤ (ì¤‘ì•™ê°’ ê¸°ë°˜)
        
        Args:
            data: ê²€ì‚¬í•  ë°ì´í„° ì‹œë¦¬ì¦ˆ
            threshold: ìˆ˜ì •ëœ Z-ì ìˆ˜ ì„ê³„ê°’ (ê¸°ë³¸: 3.5)
            
        Returns:
            ì´ìƒì¹˜ ë§ˆìŠ¤í¬ì™€ í†µê³„ ì •ë³´
        """
        median = data.median()
        mad = np.median(np.abs(data - median))  # Median Absolute Deviation
        
        if mad == 0:
            # MADê°€ 0ì¸ ê²½ìš° í‘œì¤€í¸ì°¨ ì‚¬ìš©
            modified_z_scores = np.abs(data - median) / data.std()
        else:
            modified_z_scores = 0.6745 * (data - median) / mad
        
        outlier_mask = np.abs(modified_z_scores) > threshold
        
        stats_info = {
            'method': 'Modified Z-Score',
            'median': median,
            'mad': mad,
            'threshold': threshold,
            'max_modified_zscore': np.abs(modified_z_scores).max(),
            'outlier_count': outlier_mask.sum(),
            'outlier_percentage': (outlier_mask.sum() / len(data)) * 100
        }
        
        return outlier_mask, stats_info
    
    def detect_keyword_outliers(self, data_df: pd.DataFrame, keyword: str) -> Dict:
        """íŠ¹ì • í‚¤ì›Œë“œì˜ ì´ìƒì¹˜ë¥¼ íƒì§€í•©ë‹ˆë‹¤
        
        Args:
            data_df: ë°ì´í„°í”„ë ˆì„
            keyword: ê²€ì‚¬í•  í‚¤ì›Œë“œ
            
        Returns:
            ì´ìƒì¹˜ íƒì§€ ê²°ê³¼
        """
        keyword_data = data_df[data_df['keyword'] == keyword]['ratio']
        
        # ë°ì´í„° íƒ€ì… í™•ì¸ ë° ë³€í™˜
        keyword_data = pd.to_numeric(keyword_data, errors='coerce').dropna()
        
        if len(keyword_data) < 10:
            return {
                'keyword': keyword,
                'status': 'insufficient_data',
                'data_count': len(keyword_data),
                'message': 'ì´ìƒì¹˜ íƒì§€ë¥¼ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (ìµœì†Œ 10ê°œ í•„ìš”)'
            }
        
        results = {
            'keyword': keyword,
            'data_count': len(keyword_data),
            'methods': {}
        }
        
        # IQR ë°©ë²•
        if 'iqr' in self.methods:
            outlier_mask, stats_info = self.detect_outliers_iqr(keyword_data)
            results['methods']['iqr'] = {
                'outlier_indices': keyword_data.index[outlier_mask].tolist(),
                'outlier_values': keyword_data[outlier_mask].tolist(),
                'stats': stats_info
            }
        
        # Z-Score ë°©ë²•
        if 'zscore' in self.methods:
            outlier_mask, stats_info = self.detect_outliers_zscore(keyword_data)
            results['methods']['zscore'] = {
                'outlier_indices': keyword_data.index[outlier_mask].tolist(),
                'outlier_values': keyword_data[outlier_mask].tolist(),
                'stats': stats_info
            }
        
        # Modified Z-Score ë°©ë²•
        if 'modified_zscore' in self.methods:
            outlier_mask, stats_info = self.detect_outliers_modified_zscore(keyword_data)
            results['methods']['modified_zscore'] = {
                'outlier_indices': keyword_data.index[outlier_mask].tolist(),
                'outlier_values': keyword_data[outlier_mask].tolist(),
                'stats': stats_info
            }
        
        # í•©ì˜ ê¸°ë°˜ ì´ìƒì¹˜ (2ê°œ ì´ìƒ ë°©ë²•ì—ì„œ íƒì§€ëœ ê²½ìš°)
        all_outlier_indices = set()
        for method_result in results['methods'].values():
            all_outlier_indices.update(method_result['outlier_indices'])
        
        consensus_outliers = []
        for idx in all_outlier_indices:
            detection_count = sum(1 for method_result in results['methods'].values() 
                                if idx in method_result['outlier_indices'])
            if detection_count >= 2:  # 2ê°œ ì´ìƒ ë°©ë²•ì—ì„œ íƒì§€
                consensus_outliers.append(idx)
        
        results['consensus_outliers'] = {
            'indices': consensus_outliers,
            'values': keyword_data.loc[consensus_outliers].tolist() if consensus_outliers else [],
            'count': len(consensus_outliers)
        }
        
        return results
    
    def detect_all_outliers(self, data_df: pd.DataFrame) -> Dict:
        """ëª¨ë“  í‚¤ì›Œë“œì˜ ì´ìƒì¹˜ë¥¼ íƒì§€í•©ë‹ˆë‹¤
        
        Args:
            data_df: ë°ì´í„°í”„ë ˆì„
            
        Returns:
            ì „ì²´ ì´ìƒì¹˜ íƒì§€ ê²°ê³¼
        """
        keywords = data_df['keyword'].unique()
        all_results = {}
        
        print(f"\nğŸ” ì´ìƒì¹˜ íƒì§€ ì‹œì‘ ({len(keywords)}ê°œ í‚¤ì›Œë“œ)...")
        
        for keyword in keywords:
            print(f"  ğŸ“Š {keyword} ë¶„ì„ ì¤‘...")
            result = self.detect_keyword_outliers(data_df, keyword)
            all_results[keyword] = result
            
            if result.get('status') != 'insufficient_data':
                consensus_count = result['consensus_outliers']['count']
                if consensus_count > 0:
                    print(f"    âš ï¸  í•©ì˜ ê¸°ë°˜ ì´ìƒì¹˜: {consensus_count}ê°œ")
                else:
                    print(f"    âœ… ì´ìƒì¹˜ ì—†ìŒ")
        
        # ì „ì²´ ìš”ì•½
        total_consensus_outliers = sum(r['consensus_outliers']['count'] 
                                     for r in all_results.values() 
                                     if r.get('status') != 'insufficient_data')
        
        summary = {
            'total_keywords': len(keywords),
            'analyzed_keywords': len([r for r in all_results.values() 
                                    if r.get('status') != 'insufficient_data']),
            'total_consensus_outliers': total_consensus_outliers,
            'outlier_percentage': (total_consensus_outliers / len(data_df)) * 100 if len(data_df) > 0 else 0
        }
        
        print(f"\nğŸ“‹ ì´ìƒì¹˜ íƒì§€ ì™„ë£Œ:")
        print(f"  ë¶„ì„ëœ í‚¤ì›Œë“œ: {summary['analyzed_keywords']}/{summary['total_keywords']}")
        print(f"  ë°œê²¬ëœ ì´ìƒì¹˜: {summary['total_consensus_outliers']}ê°œ")
        print(f"  ì´ìƒì¹˜ ë¹„ìœ¨: {summary['outlier_percentage']:.2f}%")
        
        return {
            'summary': summary,
            'results': all_results
        }
    
    def clean_outliers(self, data_df: pd.DataFrame, method: str = 'remove') -> pd.DataFrame:
        """ì´ìƒì¹˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤
        
        Args:
            data_df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
            method: ì²˜ë¦¬ ë°©ë²• ('remove', 'winsorize', 'interpolate')
            
        Returns:
            ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        """
        # ë¨¼ì € ì´ìƒì¹˜ íƒì§€
        outlier_results = self.detect_all_outliers(data_df)
        
        cleaned_df = data_df.copy()
        total_removed = 0
        
        for keyword, result in outlier_results['results'].items():
            if result.get('status') == 'insufficient_data':
                continue
            
            outlier_indices = result['consensus_outliers']['indices']
            
            if not outlier_indices:
                continue
            
            keyword_mask = cleaned_df['keyword'] == keyword
            outlier_mask = cleaned_df.index.isin(outlier_indices)
            target_mask = keyword_mask & outlier_mask
            
            if method == 'remove':
                # ì´ìƒì¹˜ ì œê±°
                cleaned_df = cleaned_df[~target_mask]
                total_removed += len(outlier_indices)
                
            elif method == 'winsorize':
                # ì´ìƒì¹˜ë¥¼ ê·¹ê°’ìœ¼ë¡œ ëŒ€ì²´ (winsorization)
                keyword_data = cleaned_df[keyword_mask]['ratio']
                p5 = keyword_data.quantile(0.05)
                p95 = keyword_data.quantile(0.95)
                
                cleaned_df.loc[target_mask & (cleaned_df['ratio'] < p5), 'ratio'] = p5
                cleaned_df.loc[target_mask & (cleaned_df['ratio'] > p95), 'ratio'] = p95
                
            elif method == 'interpolate':
                # ì´ìƒì¹˜ë¥¼ ë³´ê°„ë²•ìœ¼ë¡œ ëŒ€ì²´
                keyword_data = cleaned_df[keyword_mask].sort_values('date')
                ratio_series = keyword_data['ratio'].copy()
                
                for idx in outlier_indices:
                    if idx in ratio_series.index:
                        ratio_series.loc[idx] = np.nan
                
                # ì„ í˜• ë³´ê°„
                ratio_series = ratio_series.interpolate(method='linear')
                
                # ê²°ê³¼ ì ìš©
                for idx in keyword_data.index:
                    if idx in ratio_series.index:
                        cleaned_df.loc[idx, 'ratio'] = ratio_series.loc[idx]
        
        print(f"\nâœ… ì´ìƒì¹˜ ì²˜ë¦¬ ì™„ë£Œ ({method} ë°©ë²•):")
        print(f"  ì›ë³¸ ë°ì´í„°: {len(data_df)}ê°œ")
        print(f"  ì²˜ë¦¬ëœ ë°ì´í„°: {len(cleaned_df)}ê°œ")
        if method == 'remove':
            print(f"  ì œê±°ëœ ë°ì´í„°: {total_removed}ê°œ")
        
        return cleaned_df
    
    def plot_outlier_analysis(self, data_df: pd.DataFrame, keyword: str, save_plot: bool = True):
        """ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤
        
        Args:
            data_df: ë°ì´í„°í”„ë ˆì„
            keyword: ì‹œê°í™”í•  í‚¤ì›Œë“œ
            save_plot: í”Œë¡¯ ì €ì¥ ì—¬ë¶€
        """
        result = self.detect_keyword_outliers(data_df, keyword)
        
        if result.get('status') == 'insufficient_data':
            print(f"{keyword}: ì‹œê°í™”í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        keyword_data = data_df[data_df['keyword'] == keyword]
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'{keyword} ì´ìƒì¹˜ ë¶„ì„', fontsize=16)
        
        # 1. ì‹œê³„ì—´ í”Œë¡¯
        axes[0, 0].plot(keyword_data['date'], keyword_data['ratio'], 'b-', alpha=0.7, label='ë°ì´í„°')
        
        # í•©ì˜ ê¸°ë°˜ ì´ìƒì¹˜ í‘œì‹œ
        consensus_indices = result['consensus_outliers']['indices']
        if consensus_indices:
            outlier_data = keyword_data.loc[consensus_indices]
            axes[0, 0].scatter(outlier_data['date'], outlier_data['ratio'], 
                             color='red', s=50, label='ì´ìƒì¹˜', zorder=5)
        
        axes[0, 0].set_title('ì‹œê³„ì—´ ë°ì´í„°')
        axes[0, 0].set_ylabel('ê²€ìƒ‰ ë¹„ìœ¨')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ë°•ìŠ¤í”Œë¡¯
        box_data = [keyword_data['ratio']]
        axes[0, 1].boxplot(box_data, labels=[keyword])
        axes[0, 1].set_title('ë°•ìŠ¤í”Œë¡¯')
        axes[0, 1].set_ylabel('ê²€ìƒ‰ ë¹„ìœ¨')
        
        # 3. íˆìŠ¤í† ê·¸ë¨
        axes[1, 0].hist(keyword_data['ratio'], bins=20, alpha=0.7, edgecolor='black')
        axes[1, 0].axvline(keyword_data['ratio'].mean(), color='red', linestyle='--', label='í‰ê· ')
        axes[1, 0].axvline(keyword_data['ratio'].median(), color='green', linestyle='--', label='ì¤‘ì•™ê°’')
        axes[1, 0].set_title('ë¶„í¬ íˆìŠ¤í† ê·¸ë¨')
        axes[1, 0].set_xlabel('ê²€ìƒ‰ ë¹„ìœ¨')
        axes[1, 0].set_ylabel('ë¹ˆë„')
        axes[1, 0].legend()
        
        # 4. Z-score í”Œë¡¯
        z_scores = np.abs(stats.zscore(keyword_data['ratio']))
        axes[1, 1].plot(range(len(z_scores)), z_scores, 'o-', alpha=0.7)
        axes[1, 1].axhline(y=3, color='red', linestyle='--', label='ì„ê³„ê°’ (3.0)')
        axes[1, 1].set_title('Z-Score ë¶„ì„')
        axes[1, 1].set_xlabel('ë°ì´í„° í¬ì¸íŠ¸')
        axes[1, 1].set_ylabel('|Z-Score|')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_plot:
            plot_path = f"{Config.SAVE_DIR}/plots/{keyword}_outlier_analysis.png"
            plt.savefig(plot_path, dpi=Config.DPI, bbox_inches='tight')
            print(f"ì´ìƒì¹˜ ë¶„ì„ í”Œë¡¯ ì €ì¥: {plot_path}")
        
        plt.show()
    
    def get_outlier_report(self, outlier_results: Dict) -> str:
        """ì´ìƒì¹˜ íƒì§€ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
        
        Args:
            outlier_results: detect_all_outliersì˜ ê²°ê³¼
            
        Returns:
            ë¦¬í¬íŠ¸ ë¬¸ìì—´
        """
        report = "\n" + "="*50 + "\n"
        report += "ğŸ” ì´ìƒì¹˜ íƒì§€ ë¦¬í¬íŠ¸\n"
        report += "="*50 + "\n"
        
        summary = outlier_results['summary']
        report += f"ë¶„ì„ëœ í‚¤ì›Œë“œ: {summary['analyzed_keywords']}/{summary['total_keywords']}\n"
        report += f"ì´ ì´ìƒì¹˜: {summary['total_consensus_outliers']}ê°œ\n"
        report += f"ì´ìƒì¹˜ ë¹„ìœ¨: {summary['outlier_percentage']:.2f}%\n\n"
        
        # í‚¤ì›Œë“œë³„ ìƒì„¸ ê²°ê³¼
        for keyword, result in outlier_results['results'].items():
            if result.get('status') == 'insufficient_data':
                report += f"ğŸ” {keyword}: ë°ì´í„° ë¶€ì¡± ({result['data_count']}ê°œ)\n"
                continue
            
            consensus_count = result['consensus_outliers']['count']
            report += f"ğŸ” {keyword}:\n"
            report += f"  ë°ì´í„° ê°œìˆ˜: {result['data_count']}ê°œ\n"
            report += f"  í•©ì˜ ê¸°ë°˜ ì´ìƒì¹˜: {consensus_count}ê°œ\n"
            
            for method, method_result in result['methods'].items():
                method_count = len(method_result['outlier_indices'])
                percentage = method_result['stats']['outlier_percentage']
                report += f"  {method_result['stats']['method']}: {method_count}ê°œ ({percentage:.1f}%)\n"
            
            if consensus_count > 0:
                outlier_values = result['consensus_outliers']['values']
                report += f"  ì´ìƒì¹˜ ê°’: {outlier_values}\n"
            
            report += "\n"
        
        return report 