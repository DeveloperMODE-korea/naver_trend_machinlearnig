"""
ë°ì´í„° ê²€ì¦ ëª¨ë“ˆ

ì˜ˆì¸¡ê°’ ê²€ì¦, ë²”ìœ„ ì²´í¬, ë°ì´í„° ë¬´ê²°ì„±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import warnings

class DataValidator:
    """ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, valid_range: Tuple[float, float] = (0, 100)):
        """ì´ˆê¸°í™”
        
        Args:
            valid_range: ìœ íš¨í•œ ê°’ ë²”ìœ„ (ê¸°ë³¸: 0-100)
        """
        self.valid_range = valid_range
        self.validation_results = {}
    
    def validate_predictions(self, predictions: np.ndarray, keyword: str = "unknown") -> np.ndarray:
        """ì˜ˆì¸¡ê°’ì„ ê²€ì¦í•˜ê³  ë³´ì •í•©ë‹ˆë‹¤
        
        Args:
            predictions: ì˜ˆì¸¡ê°’ ë°°ì—´
            keyword: í‚¤ì›Œë“œëª… (ë¡œê¹…ìš©)
            
        Returns:
            ë³´ì •ëœ ì˜ˆì¸¡ê°’
        """
        original_predictions = predictions.copy()
        validated_predictions = predictions.copy()
        issues = []
        
        # 1. NaN/Inf ê°’ ê²€ì‚¬
        nan_mask = np.isnan(predictions) | np.isinf(predictions)
        if np.any(nan_mask):
            nan_count = np.sum(nan_mask)
            issues.append(f"NaN/Inf ê°’ {nan_count}ê°œ ë°œê²¬")
            
            # ì´ì „/ì´í›„ ê°’ì˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
            for i in range(len(validated_predictions)):
                if nan_mask[i]:
                    # ì´ì „ ìœ íš¨ê°’ ì°¾ê¸°
                    prev_val = None
                    for j in range(i-1, -1, -1):
                        if not nan_mask[j]:
                            prev_val = validated_predictions[j]
                            break
                    
                    # ì´í›„ ìœ íš¨ê°’ ì°¾ê¸°
                    next_val = None
                    for j in range(i+1, len(validated_predictions)):
                        if not nan_mask[j]:
                            next_val = validated_predictions[j]
                            break
                    
                    # ëŒ€ì²´ê°’ ê³„ì‚°
                    if prev_val is not None and next_val is not None:
                        validated_predictions[i] = (prev_val + next_val) / 2
                    elif prev_val is not None:
                        validated_predictions[i] = prev_val
                    elif next_val is not None:
                        validated_predictions[i] = next_val
                    else:
                        validated_predictions[i] = np.mean(self.valid_range)
        
        # 2. ë²”ìœ„ ë²—ì–´ë‚œ ê°’ ê²€ì‚¬
        min_val, max_val = self.valid_range
        out_of_range_mask = (validated_predictions < min_val) | (validated_predictions > max_val)
        if np.any(out_of_range_mask):
            out_count = np.sum(out_of_range_mask)
            issues.append(f"ë²”ìœ„ ë²—ì–´ë‚œ ê°’ {out_count}ê°œ ë°œê²¬ (ìœ íš¨ë²”ìœ„: {min_val}-{max_val})")
            
            # ë²”ìœ„ ë‚´ë¡œ í´ë¦¬í•‘
            validated_predictions = np.clip(validated_predictions, min_val, max_val)
        
        # 3. ê¸‰ê²©í•œ ë³€í™” ê²€ì‚¬ (ì´ìƒ ë³€ë™ë¥  > 50%)
        if len(validated_predictions) > 1:
            changes = np.abs(np.diff(validated_predictions))
            mean_change = np.mean(changes)
            threshold = mean_change + 2 * np.std(changes)
            
            extreme_changes = changes > threshold
            if np.any(extreme_changes):
                extreme_count = np.sum(extreme_changes)
                issues.append(f"ê¸‰ê²©í•œ ë³€í™” {extreme_count}ê°œ ë°œê²¬")
                
                # ê¸‰ê²©í•œ ë³€í™” ì™„í™”
                for i in range(len(extreme_changes)):
                    if extreme_changes[i]:
                        # ì´ì „ê°’ê³¼ ë‹¤ìŒê°’ì˜ ì„ í˜• ë³´ê°„
                        if i == 0:
                            validated_predictions[i+1] = (validated_predictions[i] + validated_predictions[i+2]) / 2
                        else:
                            validated_predictions[i+1] = (validated_predictions[i] + validated_predictions[i+1]) / 2
        
        # 4. ê²€ì¦ ê²°ê³¼ ì €ì¥
        self.validation_results[keyword] = {
            'original_min': np.min(original_predictions),
            'original_max': np.max(original_predictions),
            'validated_min': np.min(validated_predictions),
            'validated_max': np.max(validated_predictions),
            'corrections_made': len(issues) > 0,
            'issues': issues,
            'correction_count': np.sum(original_predictions != validated_predictions)
        }
        
        if issues:
            print(f"âš ï¸  [{keyword}] ì˜ˆì¸¡ê°’ ê²€ì¦ ê²°ê³¼:")
            for issue in issues:
                print(f"  - {issue}")
            print(f"  âœ… ì´ {self.validation_results[keyword]['correction_count']}ê°œ ê°’ ë³´ì •ë¨")
        
        return validated_predictions
    
    def validate_raw_data(self, data_df: pd.DataFrame) -> pd.DataFrame:
        """ì›ì‹œ ë°ì´í„°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤
        
        Args:
            data_df: ê²€ì¦í•  ë°ì´í„°í”„ë ˆì„
            
        Returns:
            ê²€ì¦ëœ ë°ì´í„°í”„ë ˆì„
        """
        validated_df = data_df.copy()
        total_issues = []
        
        # 1. í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì‚¬
        required_columns = ['date', 'keyword', 'ratio']
        missing_columns = [col for col in required_columns if col not in validated_df.columns]
        if missing_columns:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
        
        # 2. ë‚ ì§œ í˜•ì‹ ê²€ì‚¬
        if not pd.api.types.is_datetime64_any_dtype(validated_df['date']):
            try:
                validated_df['date'] = pd.to_datetime(validated_df['date'])
                total_issues.append("ë‚ ì§œ í˜•ì‹ ìë™ ë³€í™˜ë¨")
            except:
                total_issues.append("ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨")
        
        # 3. ratio ê°’ ê²€ì¦
        ratio_issues = []
        original_count = len(validated_df)
        
        # NaN ì œê±°
        nan_count = validated_df['ratio'].isna().sum()
        if nan_count > 0:
            validated_df = validated_df.dropna(subset=['ratio'])
            ratio_issues.append(f"NaN ê°’ {nan_count}ê°œ ì œê±°")
        
        # ìŒìˆ˜ ê°’ ì²˜ë¦¬
        negative_count = (validated_df['ratio'] < 0).sum()
        if negative_count > 0:
            validated_df.loc[validated_df['ratio'] < 0, 'ratio'] = 0
            ratio_issues.append(f"ìŒìˆ˜ ê°’ {negative_count}ê°œë¥¼ 0ìœ¼ë¡œ ë³€í™˜")
        
        # ê³¼ë„í•˜ê²Œ í° ê°’ ì²˜ë¦¬ (í‰ê· ì˜ 10ë°° ì´ìƒ)
        mean_ratio = validated_df['ratio'].mean()
        threshold = mean_ratio * 10
        extreme_count = (validated_df['ratio'] > threshold).sum()
        if extreme_count > 0:
            validated_df.loc[validated_df['ratio'] > threshold, 'ratio'] = threshold
            ratio_issues.append(f"ê·¹ê°’ {extreme_count}ê°œë¥¼ {threshold:.1f}ë¡œ ì œí•œ")
        
        # ratio ì»¬ëŸ¼ì„ float íƒ€ì…ìœ¼ë¡œ í™•ì‹¤íˆ ë³€í™˜
        validated_df['ratio'] = pd.to_numeric(validated_df['ratio'], errors='coerce')
        
        # 4. ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬
        duplicates = validated_df.duplicated(subset=['date', 'keyword']).sum()
        if duplicates > 0:
            validated_df = validated_df.drop_duplicates(subset=['date', 'keyword'])
            total_issues.append(f"ì¤‘ë³µ ë°ì´í„° {duplicates}ê°œ ì œê±°")
        
        # 5. ê²€ì¦ ê²°ê³¼ ìš”ì•½
        final_count = len(validated_df)
        removed_count = original_count - final_count
        
        print(f"\nğŸ“‹ ë°ì´í„° ê²€ì¦ ì™„ë£Œ:")
        print(f"  ì›ë³¸ ë°ì´í„°: {original_count}ê°œ")
        print(f"  ìµœì¢… ë°ì´í„°: {final_count}ê°œ")
        if removed_count > 0:
            print(f"  ì œê±°ëœ ë°ì´í„°: {removed_count}ê°œ")
        
        if ratio_issues:
            print(f"  ë¹„ìœ¨ ê°’ ë³´ì •:")
            for issue in ratio_issues:
                print(f"    - {issue}")
        
        if total_issues:
            print(f"  ê¸°íƒ€ ì´ìŠˆ:")
            for issue in total_issues:
                print(f"    - {issue}")
        
        return validated_df
    
    def get_data_quality_score(self, data_df: pd.DataFrame) -> Dict[str, float]:
        """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤
        
        Args:
            data_df: í‰ê°€í•  ë°ì´í„°í”„ë ˆì„
            
        Returns:
            í’ˆì§ˆ ì ìˆ˜ ë”•ì…”ë„ˆë¦¬
        """
        scores = {}
        
        # 1. ì™„ì„±ë„ ì ìˆ˜ (ê²°ì¸¡ê°’ ë¹„ìœ¨)
        total_cells = len(data_df) * len(data_df.columns)
        missing_cells = data_df.isnull().sum().sum()
        completeness_score = (1 - missing_cells / total_cells) * 100
        scores['ì™„ì„±ë„'] = completeness_score
        
        # 2. ì¼ê´€ì„± ì ìˆ˜ (ë°ì´í„° íƒ€ì… ë° í˜•ì‹)
        consistency_issues = 0
        # ë‚ ì§œ í˜•ì‹ í™•ì¸
        if not pd.api.types.is_datetime64_any_dtype(data_df['date']):
            consistency_issues += 1
        # ìˆ«ì í˜•ì‹ í™•ì¸
        if not pd.api.types.is_numeric_dtype(data_df['ratio']):
            consistency_issues += 1
        
        consistency_score = max(0, (1 - consistency_issues / 2) * 100)
        scores['ì¼ê´€ì„±'] = consistency_score
        
        # 3. ìœ íš¨ì„± ì ìˆ˜ (ë²”ìœ„ ë‚´ ê°’ ë¹„ìœ¨)
        valid_ratio_count = ((data_df['ratio'] >= 0) & (data_df['ratio'] <= 100)).sum()
        validity_score = (valid_ratio_count / len(data_df)) * 100
        scores['ìœ íš¨ì„±'] = validity_score
        
        # 4. ì¶©ë¶„ì„± ì ìˆ˜ (í‚¤ì›Œë“œë³„ ë°ì´í„° ê°œìˆ˜)
        keyword_counts = data_df['keyword'].value_counts()
        min_required = 12  # ìµœì†Œ 12ê°œì›” ë°ì´í„°
        sufficient_keywords = (keyword_counts >= min_required).sum()
        sufficiency_score = (sufficient_keywords / len(keyword_counts)) * 100
        scores['ì¶©ë¶„ì„±'] = sufficiency_score
        
        # 5. ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        overall_score = np.mean(list(scores.values()))
        scores['ì „ì²´ì ìˆ˜'] = overall_score
        
        return scores
    
    def get_validation_report(self) -> str:
        """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"""
        if not self.validation_results:
            return "ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        report = "\n" + "="*50 + "\n"
        report += "ğŸ“Š ë°ì´í„° ê²€ì¦ ë¦¬í¬íŠ¸\n"
        report += "="*50 + "\n"
        
        total_keywords = len(self.validation_results)
        corrected_keywords = sum(1 for r in self.validation_results.values() if r['corrections_made'])
        
        report += f"ê²€ì¦ëœ í‚¤ì›Œë“œ: {total_keywords}ê°œ\n"
        report += f"ë³´ì •ì´ í•„ìš”í•œ í‚¤ì›Œë“œ: {corrected_keywords}ê°œ\n\n"
        
        for keyword, result in self.validation_results.items():
            report += f"ğŸ” {keyword}:\n"
            report += f"  ì›ë³¸ ë²”ìœ„: {result['original_min']:.2f} ~ {result['original_max']:.2f}\n"
            report += f"  ë³´ì • ë²”ìœ„: {result['validated_min']:.2f} ~ {result['validated_max']:.2f}\n"
            
            if result['corrections_made']:
                report += f"  ë³´ì •ëœ ê°’: {result['correction_count']}ê°œ\n"
                for issue in result['issues']:
                    report += f"    - {issue}\n"
            else:
                report += f"  âœ… ê²€ì¦ í†µê³¼\n"
            report += "\n"
        
        return report 