import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import sys
from datetime import datetime, timedelta
import time
import json

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ë¡œì»¬ ëª¨ë“ˆ import
from src.config import Config
from src.collectors import NaverDataCollector, GoogleTrendsCollector, MultiPlatformCollector
from src.analysis.statistics import StatisticsAnalyzer
from src.models.ensemble_model import EnsembleModel, AdvancedEnsembleModel
from src.utils.file_utils import FileManager
# ğŸ†• ë°ì´í„° ê²€ì¦ ëª¨ë“ˆë“¤
from src.validation.data_validator import DataValidator
from src.validation.outlier_detector import OutlierDetector
from src.validation.quality_monitor import QualityMonitor
# ğŸ†• AI ë¦¬í¬íŠ¸ ëª¨ë“ˆ
from src.ai.ai_reporter import AIReporter

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë„¤ì´ë²„ ì‡¼í•‘ íŠ¸ë Œë“œ ML ë¶„ì„",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 10px;
        margin: 10px 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 10px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

def main():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ í•¨ìˆ˜"""
    
    # í—¤ë”
    st.markdown('<div style="text-align: center;"><h1>ğŸ›ï¸ ë„¤ì´ë²„ ì‡¼í•‘ íŠ¸ë Œë“œ ML ë¶„ì„ ëŒ€ì‹œë³´ë“œ</h1></div>', 
                unsafe_allow_html=True)
    st.markdown('<div style="text-align: center;"><h3>ëª¨ë“ˆí™” ë²„ì „ v2.1</h3></div>', 
                unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # í˜ì´ì§€ ì„ íƒ
        page = st.selectbox(
            "ğŸ“‹ í˜ì´ì§€ ì„ íƒ",
            ["ğŸ  í™ˆ", "ğŸ“Š ë°ì´í„° ìˆ˜ì§‘", "ğŸ“ˆ ë°ì´í„° ë¶„ì„", "ğŸ” í’ˆì§ˆ ê²€ì¦", "ğŸ¤– ML ì˜ˆì¸¡", "ğŸ§  AI ë¦¬í¬íŠ¸"]
        )
        
        st.divider()
        
        # ê³µí†µ ì„¤ì •
        st.subheader("ğŸ”§ ê³µí†µ ì„¤ì •")
        
        # í”Œë«í¼ ì„ íƒ
        platform_option = st.radio(
            "ë°ì´í„° í”Œë«í¼",
            ["ë„¤ì´ë²„ë§Œ", "êµ¬ê¸€ë§Œ", "ë„¤ì´ë²„+êµ¬ê¸€"],
            index=0
        )
        
        # í‚¤ì›Œë“œ ì…ë ¥
        keywords_input = st.text_area(
            "ë¶„ì„ í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            value="ë¬¼í‹°ìŠˆ, ë§ˆìŠ¤í¬, ìƒìˆ˜",
            height=100
        )
        keywords = [kw.strip() for kw in keywords_input.split(',') if kw.strip()]
        
        # ë‚ ì§œ ë²”ìœ„
        col1, col2 = st.columns(2)
        with col1:
            start_year = st.number_input("ì‹œì‘ ì—°ë„", min_value=2017, max_value=2024, value=2020)
        with col2:
            end_year = st.number_input("ì¢…ë£Œ ì—°ë„", min_value=2017, max_value=2024, value=2024)
        
        # API ì„¤ì • (ì ‘ê¸°/í¼ì¹˜ê¸°)
        with st.expander("ğŸ”‘ API ì„¤ì •"):
            naver_client_id = st.text_input("ë„¤ì´ë²„ Client ID", type="password")
            naver_client_secret = st.text_input("ë„¤ì´ë²„ Client Secret", type="password")
    
    # ë©”ì¸ ì½˜í…ì¸ 
    if page == "ğŸ  í™ˆ":
        show_home_page()
    elif page == "ğŸ“Š ë°ì´í„° ìˆ˜ì§‘":
        show_data_collection_page(platform_option, keywords, start_year, end_year, 
                                 naver_client_id, naver_client_secret)
    elif page == "ğŸ“ˆ ë°ì´í„° ë¶„ì„":
        show_data_analysis_page()
    elif page == "ğŸ” í’ˆì§ˆ ê²€ì¦":
        show_quality_validation_page()
    elif page == "ğŸ¤– ML ì˜ˆì¸¡":
        show_ml_prediction_page()
    elif page == "ğŸ§  AI ë¦¬í¬íŠ¸":
        show_ai_report_page()

def show_home_page():
    """í™ˆ í˜ì´ì§€"""
    st.header("ğŸ  ëŒ€ì‹œë³´ë“œ ê°œìš”")
    
    # ì†Œê°œ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### ğŸ“‹ ì‹œìŠ¤í…œ ì†Œê°œ (ê³ ê¸‰ ëª¨ë¸ í™•ì¥ ë²„ì „)
        ì´ ëŒ€ì‹œë³´ë“œëŠ” **ë„¤ì´ë²„ ì‡¼í•‘ íŠ¸ë Œë“œ**ì™€ **êµ¬ê¸€ íŠ¸ë Œë“œ** ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ 
        í‚¤ì›Œë“œë³„ ê²€ìƒ‰ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ê³  **AI ê¸°ë°˜ ê³ ë„í™”ëœ ì˜ˆì¸¡**ì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
        
        ### ğŸ†• ìµœì‹  ì—…ë°ì´íŠ¸ - ëª¨ë¸ ë‹¤ì–‘ì„± í™•ì¥
        - **ğŸ§  Transformer ëª¨ë¸**: BERT/GPT ìŠ¤íƒ€ì¼ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
        - **ğŸ“Š XGBoost/CatBoost**: ê³ ì„±ëŠ¥ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸  
        - **ğŸ”„ AutoML**: ìë™ ëª¨ë¸ ì„ íƒ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
        - **ğŸ¯ ë™ì  ê°€ì¤‘ì¹˜**: ì„±ëŠ¥ ê¸°ë°˜ ì•™ìƒë¸” ìµœì í™”
        - **âš–ï¸ ì ì‘ì  ì˜ˆì¸¡**: ì‹¤ì‹œê°„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ì¡°ì •
        
        ### ğŸ”§ í•µì‹¬ ê¸°ëŠ¥
        - **ğŸ“Š ë°ì´í„° ìˆ˜ì§‘**: ë„¤ì´ë²„ + êµ¬ê¸€ íŠ¸ë Œë“œ ìë™ ìˆ˜ì§‘
        - **ğŸ“ˆ ë¶„ì„**: ìƒê´€ê´€ê³„, ê³„ì ˆì„±, ì„±ì¥ë¥  ë¶„ì„
        - **ğŸ” í’ˆì§ˆ ê²€ì¦**: ì´ìƒì¹˜ íƒì§€, ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
        - **ğŸ¤– AI ì˜ˆì¸¡**: 
          - ğŸ”§ ê¸°ë³¸ ì•™ìƒë¸” (Prophet + LSTM)
          - âš¡ ê³ ê¸‰ ì•™ìƒë¸” (5ê°œ ëª¨ë¸ + ë™ì  ê°€ì¤‘ì¹˜)
          - ğŸ¤– AutoML ê°•í™” ì˜ˆì¸¡ (ìë™ ìµœì í™”)
        - **ğŸ§  AI ë¦¬í¬íŠ¸**: Claude AI ê¸°ë°˜ ì „ë¬¸ê°€ ìˆ˜ì¤€ ì¸ì‚¬ì´íŠ¸
        - **ğŸŒ ë‹¤ì¤‘ í”Œë«í¼**: í”Œë«í¼ ê°„ ë¹„êµ ë¶„ì„
        
        ### ğŸš€ ìƒˆë¡œìš´ ì˜ˆì¸¡ ëª¨ë¸ë“¤
        1. **ğŸ”® Transformer**: ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ ê¸°ë°˜ ê³ ê¸‰ ì‹œê³„ì—´ ì˜ˆì¸¡
        2. **ğŸŒ² XGBoost**: íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ + ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…
        3. **ğŸ± CatBoost**: ì¹´í…Œê³ ë¦¬ íŠ¹ì„± íŠ¹í™” ë¶€ìŠ¤íŒ…
        4. **ğŸ¯ ì ì‘ì  ì•™ìƒë¸”**: ì‹¤ì‹œê°„ ì„±ëŠ¥ í‰ê°€ë¡œ ìµœì  ê°€ì¤‘ì¹˜ ìë™ ì¡°ì •
        5. **ğŸ¤– AutoML**: Optuna ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ ìµœì í™”
        
        ### ğŸš€ ì‹œì‘í•˜ê¸°
        1. ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ **í‚¤ì›Œë“œ**ì™€ **ë¶„ì„ ê¸°ê°„** ì„¤ì •
        2. **ë„¤ì´ë²„ API í‚¤** ì…ë ¥ (í•„ìˆ˜)
        3. **ğŸ“Š ë°ì´í„° ìˆ˜ì§‘** í˜ì´ì§€ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘
        4. **ğŸ¤– ML ì˜ˆì¸¡**ì—ì„œ ê³ ê¸‰ ì˜ˆì¸¡ ëª¨ë“œ ì„ íƒ
        """)
    
    with col2:
        st.info("""
        ğŸ“Š **ì‹œìŠ¤í…œ ìƒíƒœ**
        - âœ… ëª¨ë“ˆí™” êµ¬ì¡° v2.1
        - âœ… TensorFlow + PyTorch ì¤€ë¹„ë¨
        - âœ… Prophet + LSTM ê¸°ë³¸ ëª¨ë¸
        - ğŸ†• Transformer ëª¨ë¸ ì§€ì›
        - ğŸ†• XGBoost + CatBoost ì§€ì›
        - ğŸ†• AutoML (Optuna) ì¤€ë¹„ë¨
        - âœ… êµ¬ê¸€ íŠ¸ë Œë“œ ì—°ë™ë¨
        - âœ… ë°ì´í„° ê²€ì¦ ëª¨ë“ˆ í™œì„±í™”
        - ğŸ§  Claude AI ë¦¬í¬í„° í™œì„±í™”
        """)
        
        st.success("""
        ğŸ¯ **ìµœì‹  ê¸°ëŠ¥**
        - ğŸš€ 5ê°œ ëª¨ë¸ ì•™ìƒë¸” ì§€ì›
        - ğŸ¯ ë™ì  ê°€ì¤‘ì¹˜ ìë™ ì¡°ì •
        - ğŸ¤– AutoML í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
        - ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ í‰ê°€
        - ğŸ” ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
        - ğŸ’¡ ì¹´í…Œê³ ë¦¬ íŠ¹ì„± ìë™ ì²˜ë¦¬
        - âš–ï¸ ìˆ˜í•™ì  ìµœì í™” ê¸°ë°˜ ê°€ì¤‘ì¹˜
        """)

def show_data_collection_page(platform_option, keywords, start_year, end_year, 
                            naver_client_id, naver_client_secret):
    """ë°ì´í„° ìˆ˜ì§‘ í˜ì´ì§€"""
    st.header("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘")
    
    # ì„¤ì • í™•ì¸
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ”§ ìˆ˜ì§‘ ì„¤ì •")
        st.write(f"**í”Œë«í¼**: {platform_option}")
        st.write(f"**í‚¤ì›Œë“œ**: {', '.join(keywords)}")
        st.write(f"**ê¸°ê°„**: {start_year}ë…„ - {end_year}ë…„")
        st.write(f"**ì˜ˆìƒ ë°ì´í„° í¬ì¸íŠ¸**: {len(keywords) * 12 * (end_year - start_year + 1)}")
    
    with col2:
        st.subheader("ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸")
        
        # API í‚¤ í™•ì¸
        api_ready = bool(naver_client_id and naver_client_secret) if "ë„¤ì´ë²„" in platform_option else True
        st.write("âœ… API í‚¤" if api_ready else "âŒ API í‚¤")
        
        # í‚¤ì›Œë“œ í™•ì¸  
        keywords_ready = len(keywords) > 0 and len(keywords) <= 10
        st.write("âœ… í‚¤ì›Œë“œ" if keywords_ready else "âŒ í‚¤ì›Œë“œ (1-10ê°œ)")
        
        # ê¸°ê°„ í™•ì¸
        period_ready = start_year <= end_year
        st.write("âœ… ê¸°ê°„" if period_ready else "âŒ ê¸°ê°„")
    
    # ìˆ˜ì§‘ ì‹¤í–‰
    if st.button("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘", type="primary"):
        if not (api_ready and keywords_ready and period_ready):
            st.error("ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”!")
            return
            
        with st.spinner("ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
            try:
                # ëª¨ë“ˆí™”ëœ ìˆ˜ì§‘ê¸° ì‚¬ìš©
                if platform_option == "ë„¤ì´ë²„ë§Œ":
                    collector = NaverDataCollector(naver_client_id, naver_client_secret)
                    result_df = collector.collect_data(keywords, start_year, end_year)
                    
                elif platform_option == "êµ¬ê¸€ë§Œ":
                    collector = GoogleTrendsCollector()
                    result_df = collector.collect_trends_data(keywords, start_year, end_year)
                    
                elif platform_option == "ë„¤ì´ë²„+êµ¬ê¸€":
                    multi_collector = MultiPlatformCollector(naver_client_id, naver_client_secret)
                    result_df = multi_collector.collect_multi_platform_data(
                        keywords, start_year, end_year, ['naver', 'google']
                    )
                
                if not result_df.empty:
                    st.success(f"ğŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ! {len(result_df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
                    
                    # ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì´ ë°ì´í„° ìˆ˜", len(result_df))
                    with col2:
                        st.metric("í‚¤ì›Œë“œ ìˆ˜", len(result_df['keyword'].unique()))
                    with col3:
                        if 'source' in result_df.columns:
                            st.metric("í”Œë«í¼ ìˆ˜", len(result_df['source'].unique()))
                        else:
                            st.metric("í”Œë«í¼", "ë„¤ì´ë²„")
                    
                    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    st.dataframe(result_df.head(), use_container_width=True)
                    
                    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                    st.session_state['data'] = result_df
                    
                else:
                    st.error("ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def show_data_analysis_page():
    """ë°ì´í„° ë¶„ì„ í˜ì´ì§€"""
    st.header("ğŸ“ˆ ë°ì´í„° ë¶„ì„")
    
    # ë°ì´í„° í™•ì¸
    if 'data' not in st.session_state:
        st.warning("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
        return
    
    data_df = st.session_state['data']
    
    st.success(f"ë¶„ì„ ë°ì´í„°: {len(data_df)}ê°œ í¬ì¸íŠ¸, {len(data_df['keyword'].unique())}ê°œ í‚¤ì›Œë“œ")
    
    # ë¶„ì„ ì˜µì…˜
    col1, col2 = st.columns(2)
    with col1:
        show_charts = st.checkbox("ğŸ“Š ì°¨íŠ¸ ìƒì„± ë° í‘œì‹œ", value=True)
        show_tables = st.checkbox("ğŸ“‹ ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”", value=True)
    
    with col2:
        show_interactive = st.checkbox("ğŸ”„ ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸", value=True)
        show_images = st.checkbox("ğŸ–¼ï¸ ì €ì¥ëœ ì´ë¯¸ì§€ í‘œì‹œ", value=True)
    
    # ë¶„ì„ ì‹¤í–‰
    if st.button("ğŸ” ì „ì²´ ë¶„ì„ ì‹œì‘", type="primary"):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            try:
                # ëª¨ë“ˆí™”ëœ ë¶„ì„ê¸° ì‚¬ìš©
                analyzer = StatisticsAnalyzer(data_df)
                
                # ê¸°ë³¸ í†µê³„ ë¶„ì„
                stats_df, yearly_avg = analyzer.basic_statistics()
                
                # ìƒê´€ê´€ê³„ ë¶„ì„
                correlation = analyzer.correlation_analysis()
                
                # ì„±ì¥ë¥  ë¶„ì„
                growth_df = analyzer.growth_rate_analysis()
                
                # ì›”ë³„ ë¶„ì„
                monthly_top = analyzer.monthly_analysis()
                
                # ë‹¤ì¤‘ í”Œë«í¼ ë¶„ì„ (í•´ë‹¹ë˜ëŠ” ê²½ìš°)
                analyzer.multi_platform_analysis()
                
                st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                
                # ê²°ê³¼ í‘œì‹œ
                if show_tables:
                    st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”")
                    
                    # ê¸°ë³¸ í†µê³„
                    if stats_df is not None:
                        st.write("**ğŸ“ˆ í‚¤ì›Œë“œë³„ ê¸°ë³¸ í†µê³„**")
                        st.dataframe(stats_df, use_container_width=True)
                    
                    # ì„±ì¥ë¥ 
                    if growth_df is not None:
                        st.write("**ğŸ“ˆ í‚¤ì›Œë“œë³„ ì„±ì¥ë¥ **")
                        st.dataframe(growth_df, use_container_width=True)
                    
                    # ìƒê´€ê´€ê³„
                    if correlation is not None:
                        st.write("**ğŸ”— í‚¤ì›Œë“œ ê°„ ìƒê´€ê´€ê³„**")
                        st.dataframe(correlation, use_container_width=True)
                
                # ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸ ìƒì„±
                if show_interactive:
                    st.subheader("ğŸ”„ ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸")
                    
                    # ì „ì²´ íŠ¸ë Œë“œ ì°¨íŠ¸
                    if not data_df.empty:
                        fig_trend = px.line(
                            data_df, 
                            x='date', 
                            y='ratio', 
                            color='keyword',
                            title='ğŸ“ˆ í‚¤ì›Œë“œë³„ ê²€ìƒ‰ íŠ¸ë Œë“œ',
                            labels={'ratio': 'ê²€ìƒ‰ ë¹„ìœ¨', 'date': 'ë‚ ì§œ'}
                        )
                        fig_trend.update_layout(height=500)
                        st.plotly_chart(fig_trend, use_container_width=True)
                    
                    # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
                    if correlation is not None and not correlation.empty:
                        fig_corr = px.imshow(
                            correlation,
                            text_auto=True,
                            aspect="auto",
                            title="ğŸ”— í‚¤ì›Œë“œ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ",
                            color_continuous_scale="RdBu_r"
                        )
                        fig_corr.update_layout(height=400)
                        st.plotly_chart(fig_corr, use_container_width=True)
                    
                    # ì„±ì¥ë¥  ë°”ì°¨íŠ¸
                    if growth_df is not None and not growth_df.empty:
                        fig_growth = px.bar(
                            growth_df,
                            x='í‚¤ì›Œë“œ',
                            y='ì„±ì¥ë¥ (%)',
                            title="ğŸ“Š í‚¤ì›Œë“œë³„ ì„±ì¥ë¥ ",
                            color='ì„±ì¥ë¥ (%)',
                            color_continuous_scale="RdYlGn"
                        )
                        fig_growth.update_layout(height=400)
                        st.plotly_chart(fig_growth, use_container_width=True)
                    
                    # ì›”ë³„ íŒ¨í„´ ë¶„ì„
                    if not data_df.empty:
                        monthly_avg = data_df.groupby(['month', 'keyword'])['ratio'].mean().reset_index()
                        fig_monthly = px.line(
                            monthly_avg,
                            x='month',
                            y='ratio',
                            color='keyword',
                            title="ğŸ“… ì›”ë³„ í‰ê·  ê²€ìƒ‰ ë¹„ìœ¨ (ê³„ì ˆì„±)",
                            labels={'ratio': 'í‰ê·  ê²€ìƒ‰ ë¹„ìœ¨', 'month': 'ì›”'}
                        )
                        fig_monthly.update_layout(height=400)
                        st.plotly_chart(fig_monthly, use_container_width=True)
                
                # ì €ì¥ëœ ì´ë¯¸ì§€ í‘œì‹œ
                if show_images:
                    st.subheader("ğŸ–¼ï¸ ë¶„ì„ ê²°ê³¼ ì´ë¯¸ì§€")
                    
                    plot_dir = os.path.join(Config.SAVE_DIR, 'plots')
                    
                    if os.path.exists(plot_dir):
                        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
                        image_files = [f for f in os.listdir(plot_dir) if f.endswith('.png')]
                        
                        if image_files:
                            # ì´ë¯¸ì§€ë¥¼ 2ì—´ë¡œ í‘œì‹œ
                            cols = st.columns(2)
                            
                            for idx, image_file in enumerate(image_files):
                                image_path = os.path.join(plot_dir, image_file)
                                
                                with cols[idx % 2]:
                                    # íŒŒì¼ëª…ì—ì„œ ì œëª© ìƒì„±
                                    title = image_file.replace('.png', '').replace('_', ' ').title()
                                    st.write(f"**{title}**")
                                    
                                    try:
                                        st.image(image_path, use_column_width=True)
                                    except Exception as e:
                                        st.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_file}")
                        else:
                            st.info("ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("plots í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì˜µì…˜
                st.subheader("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if stats_df is not None:
                        csv_stats = stats_df.to_csv(index=False)
                        st.download_button(
                            label="ğŸ“Š ê¸°ë³¸ í†µê³„ CSV",
                            data=csv_stats,
                            file_name="basic_statistics.csv",
                            mime="text/csv"
                        )
                
                with col2:
                    if correlation is not None:
                        csv_corr = correlation.to_csv()
                        st.download_button(
                            label="ğŸ”— ìƒê´€ê´€ê³„ CSV",
                            data=csv_corr,
                            file_name="correlation_matrix.csv",
                            mime="text/csv"
                        )
                
                with col3:
                    if growth_df is not None:
                        csv_growth = growth_df.to_csv(index=False)
                        st.download_button(
                            label="ğŸ“ˆ ì„±ì¥ë¥  CSV",
                            data=csv_growth,
                            file_name="growth_rate.csv",
                            mime="text/csv"
                        )
                
                # ì„¸ì…˜ì— ë¶„ì„ ê²°ê³¼ ì €ì¥ (AI ë¦¬í¬íŠ¸ì—ì„œ ì‚¬ìš©)
                st.session_state['analysis_results'] = {
                    'basic_statistics': stats_df,
                    'correlation_matrix': correlation,
                    'growth_rates': growth_df,
                    'monthly_analysis': monthly_top
                }
                
                st.info("ğŸ’¡ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ§  AI ë¦¬í¬íŠ¸ í˜ì´ì§€ì—ì„œ ì „ë¬¸ê°€ ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”!")
                
            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                import traceback
                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

def show_quality_validation_page():
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í˜ì´ì§€"""
    st.header("ğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦")
    
    # ë°ì´í„° í™•ì¸
    if 'data' not in st.session_state:
        st.warning("ê²€ì¦í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
        return
    
    data_df = st.session_state['data']
    
    st.success(f"ê²€ì¦ ë°ì´í„°: {len(data_df)}ê°œ í¬ì¸íŠ¸, {len(data_df['keyword'].unique())}ê°œ í‚¤ì›Œë“œ")
    
    # ê²€ì¦ ì˜µì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ”§ ê²€ì¦ ì˜µì…˜")
        
        validate_outliers = st.checkbox("ì´ìƒì¹˜ íƒì§€", value=True)
        validate_quality = st.checkbox("í’ˆì§ˆ í‰ê°€", value=True)
        clean_data = st.checkbox("ë°ì´í„° ì •ë¦¬", value=False)
        
        if clean_data:
            clean_method = st.selectbox(
                "ì •ë¦¬ ë°©ë²•",
                ["interpolate", "remove", "winsorize"],
                index=0
            )
    
    with col2:
        st.subheader("ğŸ“Š í’ˆì§ˆ ì„ê³„ê°’")
        
        completeness_threshold = st.slider("ì™„ì„±ë„ ìµœì†Œê°’ (%)", 70, 100, 85)
        validity_threshold = st.slider("ìœ íš¨ì„± ìµœì†Œê°’ (%)", 80, 100, 90)
        consistency_threshold = st.slider("ì¼ê´€ì„± ìµœì†Œê°’ (%)", 80, 100, 95)
        sufficiency_threshold = st.slider("ì¶©ë¶„ì„± ìµœì†Œê°’ (%)", 50, 100, 70)
        outlier_threshold = st.slider("ì´ìƒì¹˜ ìµœëŒ€ê°’ (%)", 1, 20, 5)
    
    # ê²€ì¦ ì‹¤í–‰
    if st.button("ğŸš€ í’ˆì§ˆ ê²€ì¦ ì‹œì‘", type="primary"):
        
        # ê²€ì¦ ëª¨ë“ˆ ì´ˆê¸°í™”
        validator = DataValidator()
        outlier_detector = OutlierDetector()
        
        # ì‚¬ìš©ì ì •ì˜ ì„ê³„ê°’ìœ¼ë¡œ í’ˆì§ˆ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
        quality_thresholds = {
            'completeness_min': completeness_threshold,
            'validity_min': validity_threshold,
            'consistency_min': consistency_threshold,
            'sufficiency_min': sufficiency_threshold,
            'outlier_max': outlier_threshold
        }
        quality_monitor = QualityMonitor(quality_thresholds)
        
        with st.spinner("í’ˆì§ˆ ê²€ì¦ ì¤‘..."):
            try:
                # 1. ì›ì‹œ ë°ì´í„° ê²€ì¦
                st.subheader("ğŸ“‹ ì›ì‹œ ë°ì´í„° ê²€ì¦")
                validated_df = validator.validate_raw_data(data_df)
                
                # 2. ì´ìƒì¹˜ íƒì§€
                if validate_outliers:
                    st.subheader("ğŸ” ì´ìƒì¹˜ íƒì§€")
                    outlier_results = outlier_detector.detect_all_outliers(validated_df)
                    
                    # ì´ìƒì¹˜ ìš”ì•½ í‘œì‹œ
                    summary = outlier_results['summary']
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ë¶„ì„ëœ í‚¤ì›Œë“œ", f"{summary['analyzed_keywords']}/{summary['total_keywords']}")
                    with col2:
                        st.metric("ë°œê²¬ëœ ì´ìƒì¹˜", summary['total_consensus_outliers'])
                    with col3:
                        st.metric("ì´ìƒì¹˜ ë¹„ìœ¨", f"{summary['outlier_percentage']:.2f}%")
                    
                    # í‚¤ì›Œë“œë³„ ì´ìƒì¹˜ ìƒì„¸ ì •ë³´
                    if st.expander("í‚¤ì›Œë“œë³„ ì´ìƒì¹˜ ìƒì„¸"):
                        for keyword, result in outlier_results['results'].items():
                            if result.get('status') != 'insufficient_data':
                                consensus_count = result['consensus_outliers']['count']
                                if consensus_count > 0:
                                    st.write(f"**{keyword}**: {consensus_count}ê°œ ì´ìƒì¹˜")
                                    outlier_values = result['consensus_outliers']['values']
                                    st.write(f"  ì´ìƒì¹˜ ê°’: {outlier_values}")
                else:
                    outlier_results = None
                
                # 3. ì¢…í•© í’ˆì§ˆ í‰ê°€
                if validate_quality:
                    st.subheader("ğŸ“Š ì¢…í•© í’ˆì§ˆ í‰ê°€")
                    
                    quality_assessment = quality_monitor.assess_data_quality(
                        validated_df, 
                        outlier_results=outlier_results
                    )
                    
                    # ì„¸ì…˜ì— í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ ì €ì¥ (AI ë¦¬í¬íŠ¸ì—ì„œ ì‚¬ìš©)
                    st.session_state['quality_assessment'] = quality_assessment
                    st.session_state['outlier_results'] = outlier_results
                    
                    # í’ˆì§ˆ ì ìˆ˜ í‘œì‹œ
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        score = quality_assessment['overall_score']
                        grade = quality_assessment['quality_grade']
                        
                        # ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
                        if score >= 90:
                            score_color = "green"
                        elif score >= 80:
                            score_color = "orange"
                        elif score >= 70:
                            score_color = "yellow"
                        else:
                            score_color = "red"
                        
                        st.markdown(f"""
                        <div style="text-align: center; padding: 20px; border-radius: 10px; background-color: {score_color}20;">
                            <h2 style="color: {score_color};">í’ˆì§ˆ ì ìˆ˜</h2>
                            <h1 style="color: {score_color};">{score:.1f}ì </h1>
                            <h3>{grade}</h3>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col2:
                        # í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
                        metrics = quality_assessment['quality_metrics']
                        thresholds = quality_assessment['passed_thresholds']
                        
                        st.write("**í’ˆì§ˆ ë©”íŠ¸ë¦­:**")
                        
                        # ë©”íŠ¸ë¦­ ìˆœì„œ ì •ì˜ (ë³´ê¸° ì¢‹ê²Œ)
                        metric_names = {
                            'completeness': 'ì™„ì„±ë„',
                            'validity': 'ìœ íš¨ì„±',
                            'consistency': 'ì¼ê´€ì„±',
                            'sufficiency': 'ì¶©ë¶„ì„±',
                            'freshness': 'ì‹ ì„ ë„',
                            'balance': 'ê· í˜•ì„±',
                            'outlier_percentage': 'ì´ìƒì¹˜ ë¹„ìœ¨'
                        }
                        
                        for metric, korean_name in metric_names.items():
                            if metric in metrics:
                                value = metrics[metric]
                                status = "âœ…" if thresholds.get(metric, True) else "âŒ"
                                
                                # ì´ìƒì¹˜ëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
                                if metric == 'outlier_percentage':
                                    st.write(f"{status} **{korean_name}**: {value:.1f}% (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)")
                                else:
                                    st.write(f"{status} **{korean_name}**: {value:.1f}%")
                    
                    # ê²½ê³ ì‚¬í•­
                    if quality_assessment['alerts']:
                        st.subheader("âš ï¸ ê²½ê³ ì‚¬í•­")
                        for alert in quality_assessment['alerts']:
                            severity_colors = {"high": "error", "medium": "warning", "low": "info"}
                            severity_color = severity_colors.get(alert['severity'], 'info')
                            
                            with st.container():
                                if severity_color == "error":
                                    st.error(alert['message'])
                                elif severity_color == "warning":
                                    st.warning(alert['message'])
                                else:
                                    st.info(alert['message'])
                    
                    # ê°œì„  ê¶Œì¥ì‚¬í•­
                    if quality_assessment['recommendations']:
                        st.subheader("ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­")
                        for rec in quality_assessment['recommendations']:
                            st.write(rec)
                
                # 4. ë°ì´í„° ì •ë¦¬ (ì„ íƒí•œ ê²½ìš°)
                if clean_data and outlier_results and outlier_results['summary']['total_consensus_outliers'] > 0:
                    st.subheader("ğŸ§¹ ë°ì´í„° ì •ë¦¬")
                    
                    cleaned_df = outlier_detector.clean_outliers(validated_df, method=clean_method)
                    
                    # ì •ë¦¬ ê²°ê³¼ ìš”ì•½
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ì›ë³¸ ë°ì´í„°", len(validated_df))
                    with col2:
                        st.metric("ì •ë¦¬ëœ ë°ì´í„°", len(cleaned_df))
                    
                    # ì„¸ì…˜ì— ì •ë¦¬ëœ ë°ì´í„° ì €ì¥
                    if st.button("ì •ë¦¬ëœ ë°ì´í„° ì ìš©"):
                        st.session_state['data'] = cleaned_df
                        st.success("ì •ë¦¬ëœ ë°ì´í„°ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                st.success("âœ… í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ!")
                st.info("ğŸ’¡ í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ§  AI ë¦¬í¬íŠ¸ í˜ì´ì§€ì—ì„œ ì „ë¬¸ê°€ ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”!")
                
            except Exception as e:
                st.error(f"í’ˆì§ˆ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def show_ml_prediction_page():
    """ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ í˜ì´ì§€"""
    st.header("ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡")
    
    if 'data' not in st.session_state:
        st.warning("ì˜ˆì¸¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    data_df = st.session_state['data']
    
    # ì˜ˆì¸¡ ì„¤ì •
    col1, col2 = st.columns(2)
    
    with col1:
        selected_keywords = st.multiselect(
            "ì˜ˆì¸¡í•  í‚¤ì›Œë“œ",
            options=data_df['keyword'].unique(),
            default=data_df['keyword'].unique()[:2]
        )
        
        prediction_periods = st.slider("ì˜ˆì¸¡ ê¸°ê°„ (ê°œì›”)", 3, 12, 6)
    
    with col2:
        st.subheader("ğŸš€ ì˜ˆì¸¡ ëª¨ë“œ ì„ íƒ")
        
        prediction_mode = st.radio(
            "ì˜ˆì¸¡ ë°©ë²•",
            ["ğŸ”§ ê¸°ë³¸ ì•™ìƒë¸”", "âš¡ ê³ ê¸‰ ì•™ìƒë¸” (ë™ì  ê°€ì¤‘ì¹˜)", "ğŸ¤– AutoML ê°•í™” ì˜ˆì¸¡"],
            index=1
        )
        
        if prediction_mode == "ğŸ¤– AutoML ê°•í™” ì˜ˆì¸¡":
            st.info("ğŸ”„ ìµœì  ëª¨ë¸ ìë™ ì„ íƒ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
            automl_trials = st.selectbox("AutoML ì‹œë„ íšŸìˆ˜", [10, 20, 30, 50], index=1)
        
        if prediction_mode == "âš¡ ê³ ê¸‰ ì•™ìƒë¸” (ë™ì  ê°€ì¤‘ì¹˜)":
            st.info("ğŸ¯ ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •")
            
    # ê³ ê¸‰ ì˜µì…˜
    with st.expander("ğŸ”§ ê³ ê¸‰ ì˜µì…˜"):
        show_individual_models = st.checkbox("ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ê°’ í‘œì‹œ", value=True)
        show_confidence_intervals = st.checkbox("ì‹ ë¢°êµ¬ê°„ í‘œì‹œ", value=True)
        show_model_weights = st.checkbox("ëª¨ë¸ ê°€ì¤‘ì¹˜ í‘œì‹œ", value=False)
    
    if st.button("ğŸš€ ì˜ˆì¸¡ ì‹œì‘", type="primary"):
        if not selected_keywords:
            st.warning("í‚¤ì›Œë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
            
        with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
            try:
                results = {}
                
                for keyword in selected_keywords:
                    st.write(f"ğŸ“ˆ {keyword} ì˜ˆì¸¡ ì¤‘...")
                    
                    # í‚¤ì›Œë“œë³„ ë°ì´í„° ì¶”ì¶œ
                    keyword_data = data_df[data_df['keyword'] == keyword].copy()
                    
                    if prediction_mode == "ğŸ”§ ê¸°ë³¸ ì•™ìƒë¸”":
                        # ê¸°ë³¸ ì•™ìƒë¸” ëª¨ë¸ ì‚¬ìš©
                        ensemble_model = EnsembleModel(data_df)
                        result = ensemble_model.ensemble_prediction(keyword, prediction_periods)
                        
                    elif prediction_mode == "âš¡ ê³ ê¸‰ ì•™ìƒë¸” (ë™ì  ê°€ì¤‘ì¹˜)":
                        # ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸ ì‚¬ìš©
                        advanced_model = AdvancedEnsembleModel(data_df, enable_automl=False)
                        result = advanced_model.adaptive_ensemble_prediction(
                            keyword_data, keyword, prediction_periods
                        )
                        
                        # ì•™ìƒë¸” ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
                        if show_model_weights:
                            insights = advanced_model.get_ensemble_insights()
                            st.info("ğŸ¯ ì•™ìƒë¸” ì¸ì‚¬ì´íŠ¸:\n" + "\n".join(insights))
                    
                    elif prediction_mode == "ğŸ¤– AutoML ê°•í™” ì˜ˆì¸¡":
                        # AutoML ê°•í™” ì˜ˆì¸¡
                        advanced_model = AdvancedEnsembleModel(data_df, enable_automl=True)
                        result = advanced_model.run_automl_enhanced_prediction(
                            keyword_data, keyword, prediction_periods
                        )
                    
                    if result is not None:
                        results[keyword] = result
                
                if results:
                    st.success(f"âœ… {len(results)}ê°œ í‚¤ì›Œë“œ ì˜ˆì¸¡ ì™„ë£Œ!")
                    
                    for keyword, result in results.items():
                        st.subheader(f"ğŸ“Š {keyword} ì˜ˆì¸¡ ê²°ê³¼")
                        
                        # ê¸°ë³¸ ê²°ê³¼ í‘œì‹œ (ì¤‘ë³µ ì œê±°)
                        display_columns = ['ë‚ ì§œ', 'ì•™ìƒë¸” ì˜ˆì¸¡']
                        
                        if show_confidence_intervals and 'ì‹ ë¢°ë„' in result.columns:
                            display_columns.append('ì‹ ë¢°ë„')
                        
                        if 'AutoML ê°•í™” ì˜ˆì¸¡' in result.columns:
                            display_columns.append('AutoML ê°•í™” ì˜ˆì¸¡')
                        
                        # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ê°’ í¬í•¨ (ì¤‘ë³µ ì œê±°)
                        if show_individual_models:
                            model_cols = [col for col in result.columns 
                                        if 'ì˜ˆì¸¡' in col and col not in display_columns]
                            display_columns.extend(model_cols)
                        
                        # ë©”íƒ€ ì •ë³´ (ì¤‘ë³µ ì œê±°)
                        meta_cols = ['ì‚¬ìš©ëœ ëª¨ë¸', 'ì£¼ìš” ëª¨ë¸', 'AutoML ëª¨ë¸']
                        for col in meta_cols:
                            if col in result.columns and col not in display_columns:
                                display_columns.append(col)
                        
                        # ì¤‘ë³µ ì œê±° (ìµœì¢… ì•ˆì „ì¥ì¹˜)
                        display_columns = list(dict.fromkeys(display_columns))
                        
                        # ê²°ê³¼ í‘œì‹œ
                        st.dataframe(
                            result[display_columns].round(2), 
                            use_container_width=True
                        )
                        
                        # ì‹œê°í™” (Plotly ì°¨íŠ¸)
                        try:
                            import plotly.graph_objects as go
                            
                            fig = go.Figure()
                            
                            # ì•™ìƒë¸” ì˜ˆì¸¡
                            fig.add_trace(go.Scatter(
                                x=result['ë‚ ì§œ'],
                                y=result['ì•™ìƒë¸” ì˜ˆì¸¡'],
                                mode='lines+markers',
                                name='ì•™ìƒë¸” ì˜ˆì¸¡',
                                line=dict(color='blue', width=3)
                            ))
                            
                            # AutoML ì˜ˆì¸¡ (ìˆëŠ” ê²½ìš°)
                            if 'AutoML ê°•í™” ì˜ˆì¸¡' in result.columns:
                                fig.add_trace(go.Scatter(
                                    x=result['ë‚ ì§œ'],
                                    y=result['AutoML ê°•í™” ì˜ˆì¸¡'],
                                    mode='lines+markers',
                                    name='AutoML ê°•í™” ì˜ˆì¸¡',
                                    line=dict(color='red', width=2, dash='dash')
                                ))
                            
                            # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ (ì˜µì…˜)
                            if show_individual_models:
                                colors = ['green', 'orange', 'purple', 'brown', 'pink']
                                for i, col in enumerate([c for c in result.columns if 'ì˜ˆì¸¡' in c and c not in ['ì•™ìƒë¸” ì˜ˆì¸¡', 'AutoML ê°•í™” ì˜ˆì¸¡']]):
                                    fig.add_trace(go.Scatter(
                                        x=result['ë‚ ì§œ'],
                                        y=result[col],
                                        mode='lines',
                                        name=col,
                                        line=dict(color=colors[i % len(colors)], width=1, dash='dot'),
                                        opacity=0.7
                                    ))
                            
                            fig.update_layout(
                                title=f'{keyword} ì˜ˆì¸¡ ê²°ê³¼',
                                xaxis_title='ë‚ ì§œ',
                                yaxis_title='ê²€ìƒ‰ ë¹„ìœ¨',
                                height=400,
                                hovermode='x unified'
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                            
                        except ImportError:
                            st.info("ì‹œê°í™”ë¥¼ ìœ„í•´ì„œëŠ” plotly íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    
                    # ì„¸ì…˜ì— ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ (AI ë¦¬í¬íŠ¸ì—ì„œ ì‚¬ìš©)
                    st.session_state['prediction_results'] = results
                    st.session_state['prediction_mode'] = prediction_mode
                    
                    # ê²°ê³¼ ìš”ì•½
                    st.subheader("ğŸ“‹ ì˜ˆì¸¡ ìš”ì•½")
                    
                    summary_data = []
                    for keyword, result in results.items():
                        avg_prediction = result['ì•™ìƒë¸” ì˜ˆì¸¡'].mean()
                        trend = "ìƒìŠ¹" if result['ì•™ìƒë¸” ì˜ˆì¸¡'].iloc[-1] > result['ì•™ìƒë¸” ì˜ˆì¸¡'].iloc[0] else "í•˜ë½"
                        
                        if 'AutoML ê°•í™” ì˜ˆì¸¡' in result.columns:
                            automl_avg = result['AutoML ê°•í™” ì˜ˆì¸¡'].mean()
                            summary_data.append({
                                'í‚¤ì›Œë“œ': keyword,
                                'ì•™ìƒë¸” í‰ê· ': f"{avg_prediction:.2f}",
                                'AutoML í‰ê· ': f"{automl_avg:.2f}",
                                'íŠ¸ë Œë“œ': trend,
                                'í‰ê·  ì‹ ë¢°ë„': f"{result['ì‹ ë¢°ë„'].mean():.1f}%" if 'ì‹ ë¢°ë„' in result.columns else "N/A"
                            })
                        else:
                            summary_data.append({
                                'í‚¤ì›Œë“œ': keyword,
                                'í‰ê·  ì˜ˆì¸¡ê°’': f"{avg_prediction:.2f}",
                                'íŠ¸ë Œë“œ': trend,
                                'í‰ê·  ì‹ ë¢°ë„': f"{result['ì‹ ë¢°ë„'].mean():.1f}%" if 'ì‹ ë¢°ë„' in result.columns else "N/A"
                            })
                    
                    summary_df = pd.DataFrame(summary_data)
                    st.dataframe(summary_df, use_container_width=True)
                    
                    st.info("ğŸ’¡ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ§  AI ë¦¬í¬íŠ¸ í˜ì´ì§€ì—ì„œ ì „ë¬¸ê°€ ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”!")
                else:
                    st.error("ì˜ˆì¸¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
                # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ì›ì¸ê³¼ í•´ê²° ë°©ë²• ì•ˆë‚´
                with st.expander("ğŸ”§ ì˜¤ë¥˜ í•´ê²° ë°©ë²•"):
                    st.markdown("""
                    **ì¼ë°˜ì ì¸ ì˜¤ë¥˜ì™€ í•´ê²° ë°©ë²•:**
                    
                    1. **ì¤‘ë³µ ì»¬ëŸ¼ëª… ì˜¤ë¥˜**: í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.
                    
                    2. **ëª¨ë¸ íƒ€ì… ì§€ì› ì˜¤ë¥˜**: 
                       - Transformer/XGBoost/CatBoost ëª¨ë¸ì´ ì‹¤íŒ¨í•´ë„ Prophet+LSTMì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.
                       - ê¸°ë³¸ ì•™ìƒë¸” ëª¨ë“œë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.
                    
                    3. **ë°ì´í„° ë¶€ì¡± ì˜¤ë¥˜**: 
                       - ë” ë§ì€ í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê±°ë‚˜
                       - ë¶„ì„ ê¸°ê°„ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.
                    
                    4. **í…ì„œ í¬ê¸° ë¶ˆì¼ì¹˜**: 
                       - Transformer ëª¨ë¸ì˜ ì•Œë ¤ì§„ ì´ìŠˆì…ë‹ˆë‹¤.
                       - ê³ ê¸‰ ì•™ìƒë¸”ì—ì„œ Prophet+LSTMë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
                    
                    5. **íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë¬¸ì œ**: 
                       ```bash
                       pip install -r requirements.txt
                       ```
                    
                    **ê¶Œì¥ì‚¬í•­**: 
                    - ğŸ”§ ê¸°ë³¸ ì•™ìƒë¸” ëª¨ë“œëŠ” í•­ìƒ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
                    - âš¡ ê³ ê¸‰ ì•™ìƒë¸”ì€ Prophet+LSTM ì¡°í•©ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
                    """)
                
                # ê¸°ë³¸ ì•™ìƒë¸”ë¡œ ì¬ì‹œë„ ì œì•ˆ
                if prediction_mode != "ğŸ”§ ê¸°ë³¸ ì•™ìƒë¸”":
                    st.info("ğŸ’¡ ë¬¸ì œê°€ ì§€ì†ë˜ë©´ 'ğŸ”§ ê¸°ë³¸ ì•™ìƒë¸”' ëª¨ë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”. ì´ ëª¨ë“œëŠ” Prophet+LSTMë§Œ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")

def show_ai_report_page():
    """AI ë¦¬í¬íŠ¸ í˜ì´ì§€"""
    st.header("ğŸ§  Claude AI ì „ë¬¸ê°€ ë¦¬í¬íŠ¸")
    
    # ë°ì´í„° í™•ì¸
    if 'data' not in st.session_state:
        st.warning("ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
        return
    
    data_df = st.session_state['data']
    
    # AI ë¦¬í¬í„° ì„¤ì •
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.success(f"ë¶„ì„ ë°ì´í„°: {len(data_df)}ê°œ í¬ì¸íŠ¸, {len(data_df['keyword'].unique())}ê°œ í‚¤ì›Œë“œ")
        
        # ì‚°ì—… ë¶„ì•¼ ì„ íƒ
        industry_context = st.selectbox(
            "ğŸ­ ì‚°ì—… ë¶„ì•¼",
            ["ì¼ë°˜ ì†Œë¹„ì¬", "ì‹í’ˆ/ìŒë£Œ", "ìƒí™œìš©í’ˆ", "í™”ì¥í’ˆ/ë·°í‹°", "íŒ¨ì…˜/ì˜ë¥˜", "ì „ìì œí’ˆ", "ê±´ê°•/ì˜ë£Œ", "ê¸°íƒ€"],
            index=0
        )
        
        # ë¦¬í¬íŠ¸ ìœ í˜• ì„ íƒ
        report_types = st.multiselect(
            "ğŸ“„ ìƒì„±í•  ë¦¬í¬íŠ¸ ìœ í˜•",
            ["ğŸ“Š ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸", "ğŸ”® ì˜ˆì¸¡ ë¶„ì„ ë¦¬í¬íŠ¸", "ğŸ” í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸", "ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸"],
            default=["ğŸ“Š ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸"]
        )
    
    with col2:
        st.info("""
        ğŸ§  **Claude AI ë¦¬í¬í„°**
        - ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¶„ì„
        - ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì œê³µ
        - ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­
        - í•œêµ­ ì‹œì¥ íŠ¹í™” í•´ì„
        """)
        
        # API í‚¤ ì„¤ì •
        claude_api_key = st.text_input(
            "ğŸ”‘ Claude API Key", 
            type="password",
            help="Claude AI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. Anthropic ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
    
    # AI ë¦¬í¬íŠ¸ ìƒì„±
    if st.button("ğŸš€ AI ë¦¬í¬íŠ¸ ìƒì„±", type="primary"):
        if not claude_api_key:
            st.error("Claude API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        
        if not report_types:
            st.error("ìƒì„±í•  ë¦¬í¬íŠ¸ ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”!")
            return
        
        try:
            # AI ë¦¬í¬í„° ì´ˆê¸°í™”
            ai_reporter = AIReporter(api_key=claude_api_key)
            
            if not ai_reporter.is_available():
                st.error("Claude AI ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return
            
            # ê° ë¦¬í¬íŠ¸ ìœ í˜•ë³„ë¡œ ìƒì„±
            for report_type in report_types:
                with st.expander(f"{report_type}", expanded=True):
                    with st.spinner(f"{report_type} ìƒì„± ì¤‘..."):
                        
                        if report_type == "ğŸ“Š ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸":
                            # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
                            analyzer = StatisticsAnalyzer(data_df)
                            
                            # ìƒê´€ê´€ê³„ ë¶„ì„
                            pivot_df = data_df.pivot_table(
                                index='date', columns='keyword', values='ratio'
                            ).fillna(0)
                            correlation_matrix = pivot_df.corr() if not pivot_df.empty else None
                            
                            # ì„±ì¥ë¥  ë¶„ì„
                            keywords = data_df['keyword'].unique()
                            growth_rates = []
                            for keyword in keywords:
                                keyword_data = data_df[data_df['keyword'] == keyword].sort_values('date')
                                if len(keyword_data) >= 12:
                                    first_year = keyword_data.iloc[:12]['ratio'].mean()
                                    last_year = keyword_data.iloc[-12:]['ratio'].mean()
                                    growth_rate = ((last_year - first_year) / first_year) * 100 if first_year > 0 else 0
                                    growth_rates.append({'í‚¤ì›Œë“œ': keyword, 'ì„±ì¥ë¥ (%)': growth_rate})
                            
                            growth_df = pd.DataFrame(growth_rates) if growth_rates else None
                            
                            # AI ë¦¬í¬íŠ¸ ìƒì„±
                            report = ai_reporter.generate_data_analysis_report(
                                data_df, 
                                correlation_matrix=correlation_matrix,
                                growth_rates=growth_df
                            )
                            
                            st.markdown(report)
                            
                            # ì €ì¥ ì˜µì…˜
                            if st.button(f"ğŸ’¾ {report_type} ì €ì¥", key=f"save_analysis"):
                                saved_path = ai_reporter.save_report(report, "analysis")
                                if saved_path:
                                    st.success(f"ë¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {saved_path}")
                        
                        elif report_type == "ğŸ”® ì˜ˆì¸¡ ë¶„ì„ ë¦¬í¬íŠ¸":
                            # ì˜ˆì¸¡ ê²°ê³¼ê°€ ì„¸ì…˜ì— ìˆëŠ”ì§€ í™•ì¸
                            if 'prediction_results' in st.session_state:
                                prediction_results = st.session_state['prediction_results']
                                
                                report = ai_reporter.generate_prediction_report(prediction_results)
                                st.markdown(report)
                                
                                if st.button(f"ğŸ’¾ {report_type} ì €ì¥", key=f"save_prediction"):
                                    saved_path = ai_reporter.save_report(report, "prediction")
                                    if saved_path:
                                        st.success(f"ë¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {saved_path}")
                            else:
                                st.warning("ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ML ì˜ˆì¸¡ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                        
                        elif report_type == "ğŸ” í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸":
                            # í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ê°€ ì„¸ì…˜ì— ìˆëŠ”ì§€ í™•ì¸
                            if 'quality_assessment' in st.session_state:
                                quality_assessment = st.session_state['quality_assessment']
                                outlier_results = st.session_state.get('outlier_results')
                                
                                report = ai_reporter.generate_quality_report(quality_assessment, outlier_results)
                                st.markdown(report)
                                
                                if st.button(f"ğŸ’¾ {report_type} ì €ì¥", key=f"save_quality"):
                                    saved_path = ai_reporter.save_report(report, "quality")
                                    if saved_path:
                                        st.success(f"ë¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {saved_path}")
                            else:
                                st.warning("í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í’ˆì§ˆ ê²€ì¦ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                        
                        elif report_type == "ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸":
                            keywords = data_df['keyword'].unique().tolist()
                            
                            report = ai_reporter.generate_business_insights(
                                keywords, data_df, industry_context
                            )
                            st.markdown(report)
                            
                            if st.button(f"ğŸ’¾ {report_type} ì €ì¥", key=f"save_business"):
                                saved_path = ai_reporter.save_report(report, "business")
                                if saved_path:
                                    st.success(f"ë¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {saved_path}")
            
            st.success("âœ… AI ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
            
        except Exception as e:
            st.error(f"AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            st.info("API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€, ê·¸ë¦¬ê³  Claude API ì„œë¹„ìŠ¤ê°€ ì •ìƒì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main() 